{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should reorder a bit notebook and clean it, and write basis of pipeline\n",
    "\n",
    "1. Construct `stop_times_zurich` (now it uses the graph to get nodes, but unecessary), cache it\n",
    "2. Planner, when user asks journey:\n",
    "    1. Create graph (2 hours before arrival)\n",
    "    2. Create 2nd graph with only stations and edges reachable from Zürich\n",
    "    3. Compute paths\n",
    "    4. Find shortest path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup:\n",
    "\n",
    "First we setup our spark application and load the necessary data containing information about specific transit information:  \n",
    "- `stop_times.txt` : arrival and departure times at stops\n",
    "- `stops.txt` : information about stops \n",
    "- `trips.txt` : information about journeys\n",
    "- `calendar.txt` : information about which servcies are active on which dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'dslab-group_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>4896</td><td>application_1587988164357_1532</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1532/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1532_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4916</td><td>application_1587988164357_1552</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1552/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1552_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4957</td><td>application_1587988164357_1594</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1594/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1594_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4968</td><td>application_1587988164357_1605</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1605/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1605_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4970</td><td>application_1587988164357_1607</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1607/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1607_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4971</td><td>application_1587988164357_1608</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1608/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1608_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4973</td><td>application_1587988164357_1610</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1610/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1610_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4974</td><td>application_1587988164357_1611</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1611/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1611_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4975</td><td>application_1587988164357_1612</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1587988164357_1612\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster065.iccluster.epfl.ch:45454/container_e05_1587988164357_1612_01_000001/container_e05_1587988164357_1612_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4976</td><td>application_1587988164357_1613</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1613/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1613_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4977</td><td>application_1587988164357_1614</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1614/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1614_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4978</td><td>application_1587988164357_1615</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1615/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1615_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4980</td><td>application_1587988164357_1617</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1617/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1617_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4981</td><td>application_1587988164357_1618</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1618/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1618_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4983</td><td>application_1587988164357_1620</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1620/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1620_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4985</td><td>application_1587988164357_1622</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1622/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1622_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4986</td><td>application_1587988164357_1623</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1623/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1623_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4987</td><td>application_1587988164357_1624</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1624/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1624_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4988</td><td>application_1587988164357_1625</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1625/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1587988164357_1625_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>4989</td><td>application_1587988164357_1626</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1587988164357_1626/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster067.iccluster.epfl.ch:45454/container_e05_1587988164357_1626_01_000001/container_e05_1587988164357_1626_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tInvalid status code '500' from http://iccluster044.iccluster.epfl.ch:8998/sessions with error payload: \"java.io.IOException: Could not get block locations. Source file \\\"/livy2-recovery/v1/interactive/state.tmp\\\" - Aborting...block==null\".\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from geopy.distance import distance as geo_distance\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType\n",
    "from networkx.algorithms.shortest_paths.weighted import dijkstra_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tInvalid status code '500' from http://iccluster044.iccluster.epfl.ch:8998/sessions with error payload: \"java.io.IOException: Could not get block locations. Source file \\\"/livy2-recovery/v1/interactive/state.tmp\\\" - Aborting...block==null\".\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "# Loading data, these are snapshots of the all available data\n",
    "# Calendar and trips are useful to filter the other dataframe according to the day\n",
    "\n",
    "stop_times = spark.read.format('orc').load('/data/sbb/timetables/orc/stop_times/000000_0')\n",
    "stops = spark.read.format('orc').load('/data/sbb/timetables/orc/stops/000000_0')\n",
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing: \n",
    "\n",
    "Here, we pre-process the data to correspond to the following criteria:\n",
    "- only consider journeys at reasonable hours of the day, and on a typical business day, and assuming the schedule of May 13-17, 2019\n",
    "- allow short (max 500m \"As the Crows Flies\") walking distances for transfers between two stations, and assume a walking speed of 50m/1min on a straight line, regardless of obstacles, human-built or natural, such as building, highways, rivers, or lakes\n",
    "- only consider journeys that start and end on known station coordinates (train station, bus stops, etc.), never from a random location\n",
    "- only consider stations in a 15km radius of Zürich's train station, Zürich HB (8503000), (lat, lon) = (47.378177, 8.540192)\n",
    "- only consider stations in the 15km radius that are reachable from Zürich HB, either directly, or via transfers through other stations within the area\n",
    "- assume that the timetables remain unchanged throughout the 2018 - 2019 period\n",
    "\n",
    "Filtering criteria for later use (e.g. probability intervals and planner):\n",
    "- assuming that delays or travel times on the public transport network are uncorrelated with one another\n",
    "- once a route is computed, a traveller is expected to follow the planned routes to the end, or until it fails (i.e. miss a connection)\n",
    "- planner will not need to mitigate the traveller's inconvenience if a plan fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop times during rush-hour: \n",
    "\n",
    "Only consider journeys at reasonable hours of the day, thus we take only stop times that are in the window of rush-hour (e.g. from 8 a.m. to 8 p.m.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stop_times to be only in 08:00-19:59:\n",
    "stop_times = stop_times.where((col('departure_time') >= '08:00:00') \n",
    "                              & (col('departure_time') <= '19:59:59'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations around Zürich HB:\n",
    "\n",
    "Only consider stations in a 15km radius of Zürich's train station (Zürich HB). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get the geolocation of Zürich Hauptbahnhof to be able to calculate the distance of the other stations to the Hauptbahnhof. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zurich_pos = stops.where(column('stop_name') == 'Zürich HB').select('stop_lat', 'stop_lon').collect()\n",
    "zurich_pos = (zurich_pos[0][0], zurich_pos[0][1])\n",
    "print('Location of Zürich Hauptbahnhof (lat, lon) :'+str(zurich_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zurich_distance(x, y):\n",
    "    \"\"\"zurich_distance: returns the distance of a station to Zurich HB\n",
    "    @input: (lat,lon) of a station\n",
    "    @output: distance in km to Zurich HB\n",
    "    \"\"\"\n",
    "    return geo_distance(zurich_pos, (x,y)).km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a dataframe `stops_zurich` of the stations where we add a column for the distance to Zurich HB. In that dataframe, we keep only those that are in a radisu of 15km to the HB. The same filter is applied to the `stop_times` df mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter stops:\n",
    "stops_distance = stops.rdd.map(lambda x: (x['stop_id'], zurich_distance(x['stop_lat'], x['stop_lon'])))\n",
    "stops_distance = spark.createDataFrame(stops_distance.map(lambda r: Row(stop_id=r[0], \n",
    "                                                                        zurich_distance=r[1])))\n",
    "\n",
    "stops_distance = stops_distance.filter(column('zurich_distance') <= 15)\n",
    "\n",
    "print('There are '+str(stops_distance.count())+' stops in a radius of 15km around Zurich HB')\n",
    "\n",
    "# add distance to HB to stops info and keep only in radius of 15km\n",
    "stops_zurich = stops_distance.join(stops, on='stop_id')\n",
    "\n",
    "# keep only stop times in radius of 15km of Zurich\n",
    "stop_times = stop_times.join(stops_distance.select('stop_id'), on='stop_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bizarre**: je voulais prendre les trips dans le rayon de 15km seulement mais bizarrement ça fait un dataframe plus grand que trips,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trips_zurich = trips.join(stop_times.select('trip_id').distinct().count(), on = 'trip_id', how = 'inner')\n",
    "trips_zurich.count()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only trips in radius of 15km of Zurich\n",
    "#trips_zurich = trips.join(stop_times.select('trip_id').distinct(), on = 'trip_id', how = 'inner')\n",
    "\n",
    "# WEIRD : why is trips_zurich.count() > trips.count() ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache it to save time:\n",
    "stop_times.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at the data we have so far: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop times in Zurich: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trips in Zurich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stops in Zurich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_zurich.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calendar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a network:\n",
    "\n",
    "From the pre-processed data, we would like to create a network where each node is a station and each edge between two nodes corresponds to a possible trip. \n",
    "\n",
    "A node will have the following attributes:\n",
    "- stop_name: name of the station (e.g. Zurich HB)\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "An edge will have the following attributes:\n",
    "- dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a function that returns all services that operate on certain days (as some of them might not operate on weekends for example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: ? \n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a **multigraph** (e.g. more than one edge allowed between two nodes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "\n",
    "nodes = stops_zurich.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()\n",
    "graph.add_nodes_from(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def convertToMinute(s):\n",
    "    h, m, _ = s.split(':')\n",
    "    h,m = int(h), int(m)\n",
    "    \n",
    "    return h*60+m\n",
    "\n",
    "# Keep only travels around zurich\n",
    "nodes_list = list(graph.nodes())\n",
    "stop_times_zurich = stop_times.filter(column('stop_id').isin(nodes_list))\n",
    "print('Number of stop times around zurich:', stop_times_zurich.count())\n",
    "# Convert time information to minutes elapsed since 0am\n",
    "stop_times_zurich = stop_times_zurich.withColumn('arrival_time', convertToMinute(column('arrival_time')))\n",
    "stop_times_zurich = stop_times_zurich.withColumn('departure_time', convertToMinute(column('departure_time')))\n",
    "# Add next stop to dataframe\n",
    "stop_times_zurich_2 = (stop_times_zurich.withColumn('stop_sequence_prev', column('stop_sequence')-1)\n",
    "                       .select('trip_id',\n",
    "                               column('stop_id').alias('next_stop'),\n",
    "                               column('stop_sequence_prev').alias('stop_sequence'),\n",
    "                               column('arrival_time').alias('next_arrival_time')))\n",
    "# Add trip duration\n",
    "stop_times_zurich = stop_times_zurich.join(stop_times_zurich_2, on=['trip_id', 'stop_sequence']).orderBy('trip_id', 'stop_sequence')\n",
    "stop_times_zurich = stop_times_zurich.withColumn('trip_duration', column('next_arrival_time')-column('departure_time'))\n",
    "stop_times_zurich = stop_times_zurich.select('trip_id', 'stop_id', 'arrival_time', 'departure_time', 'next_stop', 'trip_duration')\n",
    "stop_times_zurich.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trip_duration = 2 #duration in hour \n",
    "def filter_edge_on_time(edges_df, day_id, hour, minute):\n",
    "    edges_df = edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    arrival_minute = hour*60+minute\n",
    "    min_dep_time = arrival_minute - 60*60*max_trip_duration\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_minute))\n",
    "\n",
    "    return edges_df\n",
    "\n",
    "# Example of graph construction: Wednesday arrival at 11:30:00\n",
    "edges = (filter_edge_on_time(stop_times_zurich, 2, 11, 30)\n",
    "         .rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                          'time': float(r['departure_time'])})).collect())\n",
    "print('Number of edges:', len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = graph.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_ids_zurich = stops_zurich.where(col('stop_name') == 'Zürich HB').select('stop_id').rdd.flatMap(lambda x: x).collect()\n",
    "stop_ids_zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_reachable_from_zurich = set(stop_ids_zurich)\n",
    "\n",
    "for id_ in stop_ids_zurich:\n",
    "    nodes_reachable_from_zurich = nodes_reachable_from_zurich.union(nx.descendants(graph, id_))\n",
    "    \n",
    "new_edges = [e for e in graph.edges(data=True) if e[0] in nodes_reachable_from_zurich and e[1] in nodes_reachable_from_zurich]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_zurich = nx.MultiDiGraph()\n",
    "graph_zurich.add_nodes_from(nodes_reachable_from_zurich)\n",
    "_ = graph_zurich.add_edges_from(new_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.descendants(graph_zurich, '8503000:0:10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dijkstra_path(graph_zurich, '8503000:0:10', '8502208:0:3', weight='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = nx.all_simple_paths(graph_zurich, '8503000:0:10', '8502208:0:3')\n",
    "\n",
    "for path in gen:\n",
    "    print(path, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.out_edges('8503000:0:10', data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_edges(edges, time):\n",
    "    edges = [edge for edge in edges if edge[2]['time'] >= time]\n",
    "    \n",
    "    destinations = set([edge[1] for edge in edges])\n",
    "    earliest_edges = []\n",
    "    \n",
    "    for destination in destinations:\n",
    "        edges_to_dest = [edge for edge in edges if edge[1] == destination]\n",
    "        earliest_edge = sorted(edges_to_dest, key=lambda edge: edge[2]['time'] + edge[2]['duration'])[0]\n",
    "        earliest_edges.append(earliest_edge)\n",
    "    \n",
    "    return earliest_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(graph, source, target, time, prev_path=[], num_hops=0, max_num_hops=4):\n",
    "    if source == target:\n",
    "        return [prev_path]\n",
    "    elif num_hops >= max_num_hops:\n",
    "        return None\n",
    "    else:\n",
    "        out_edges = graph.out_edges(source, data=True)\n",
    "        out_edges = filter_edges(out_edges, time)\n",
    "        # Should manually check\n",
    "        print(time)\n",
    "        print(out_edges)\n",
    "        paths = []\n",
    "        \n",
    "        for out_edge in out_edges:\n",
    "            new_paths = get_paths(graph, out_edge[1], target, time=out_edge[2]['time']+out_edge[2]['duration'], prev_path=prev_path+[source], num_hops=num_hops+1)\n",
    "            if new_paths is not None:\n",
    "                paths = paths + new_paths\n",
    "                    \n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_edges = graph.out_edges('8503006:0:6', data=True)\n",
    "out_edges = [edge for edge in out_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dijkstra_path(graph_zurich, '8503000:0:10', '8503011:0:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.descendants(graph_zurich, '8503000:0:10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_paths(graph_zurich, '8503000:0:10', '8503202:0:4', 570, max_num_hops=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for stop_times filtered on wednesday\n",
    "stop_times_wed = day_trips(2).join(stop_times, on='trip_id')\n",
    "stop_times_wed.show(5)\n",
    "\n",
    "stop_times_wed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't run, the count makes it timeout. I asked Tao why\n",
    "#print('Full stop times have', stop_times.count(), 'entries, filtered has', stop_times_wed.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for r in stops_zurich.collect():\n",
    "#    if r['stop_id'] == '8503000':\n",
    "#        print((r['stop_id'], {'name': r['stop_name'].encode('utf-8'), 'lat': r['stop_lat'], 'lon': r['stop_lon']}))\n",
    "#        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
