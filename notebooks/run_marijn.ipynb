{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run:\n",
    "Only notebook to run ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'pyFiles': ['/user/gottraux/dijkstra_algorithms.py'], 'conf': {'spark.app.name': 'dslab-group_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8869</td><td>application_1589299642358_3401</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3401/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3401_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8874</td><td>application_1589299642358_3406</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3406/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3406_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8875</td><td>application_1589299642358_3407</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3407/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3407_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8877</td><td>application_1589299642358_3409</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3409/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3409_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8880</td><td>application_1589299642358_3412</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3412/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3412_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8883</td><td>application_1589299642358_3415</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3415/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3415_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8884</td><td>application_1589299642358_3416</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3416/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3416_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8885</td><td>application_1589299642358_3417</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3417/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3417_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8886</td><td>application_1589299642358_3418</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3418/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3418_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8888</td><td>application_1589299642358_3420</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3420/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3420_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8889</td><td>application_1589299642358_3421</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3421/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3421_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8890</td><td>application_1589299642358_3422</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3422/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3422_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8891</td><td>application_1589299642358_3423</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3423/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3423_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8892</td><td>application_1589299642358_3424</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_3424\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster069.iccluster.epfl.ch:45454/container_e06_1589299642358_3424_01_000001/container_e06_1589299642358_3424_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8895</td><td>application_1589299642358_3427</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3427/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3427_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8896</td><td>application_1589299642358_3428</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3428/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3428_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8897</td><td>application_1589299642358_3429</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3429/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3429_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8899</td><td>application_1589299642358_3431</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3431/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3431_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8900</td><td>application_1589299642358_3432</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_3432\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster066.iccluster.epfl.ch:45454/container_e06_1589299642358_3432_01_000001/container_e06_1589299642358_3432_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8901</td><td>application_1589299642358_3433</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3433/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3433_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8902</td><td>application_1589299642358_3434</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3434/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3434_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8903</td><td>application_1589299642358_3435</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3435/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3435_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8904</td><td>application_1589299642358_3436</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3436/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3436_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8905</td><td>application_1589299642358_3437</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3437/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3437_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"pyFiles\": [\"/user/gottraux/dijkstra_algorithms.py\"],\n",
    " \"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8906</td><td>application_1589299642358_3438</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3438/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3438_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\"\"\"\n",
    "To load (or reload) into hdfs:\n",
    "hdfs dfs -rm /user/${JUPYTERHUB_USER}/dijkstra_algorithms.py 2>/dev/null\n",
    "hdfs dfs -copyFromLocal notebooks/dijkstra_algorithms.py /user/${JUPYTERHUB_USER}/\n",
    "\"\"\"\n",
    "from dijkstra_algorithms import *\n",
    "\n",
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import pandas as pd\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "#username = 'gottraux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "stop_times = spark.read.format('orc').load('/data/sbb/timetables/orc/stop_times/000000_0')\n",
    "stops = spark.read.format('orc').load('/data/sbb/timetables/orc/stops/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges_with_mean_and_std_sec.orc\".format(username))\n",
    "\n",
    "#durations_dicts = json.loads(sc.textFile('/user/{}/durations_for_confidence_.json'.format(username)).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+------------+--------------+---------+-------------+----+----+\n",
      "|             trip_id|stop_id|train_type|arrival_time|departure_time|next_stop|trip_duration|mean| std|\n",
      "+--------------------+-------+----------+------------+--------------+---------+-------------+----+----+\n",
      "|30.TA.30-24-Y-j19...|8503111|       Bus|         496|           496|  8503102|          4.0|null|null|\n",
      "|34.TA.30-24-Y-j19...|8503111|       Bus|         539|           539|  8503102|          4.0|null|null|\n",
      "|31.TA.30-31-Y-j19...|8503111|       Bus|         532|           532|  8503103|          5.0|null|null|\n",
      "+--------------------+-------+----------+------------+--------------+---------+-------------+----+----+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "edges_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges_df = edges_df.withColumnRenamed('stop_id', 'temp').withColumnRenamed('next_stop', 'stop_id').withColumnRenamed('temp', 'next_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+------------+--------------+-------+-------------+----+----+\n",
      "|             trip_id|next_stop|train_type|arrival_time|departure_time|stop_id|trip_duration|mean| std|\n",
      "+--------------------+---------+----------+------------+--------------+-------+-------------+----+----+\n",
      "|30.TA.30-24-Y-j19...|  8503111|       Bus|         496|           496|8503102|          4.0|null|null|\n",
      "|34.TA.30-24-Y-j19...|  8503111|       Bus|         539|           539|8503102|          4.0|null|null|\n",
      "|31.TA.30-31-Y-j19...|  8503111|       Bus|         532|           532|8503103|          5.0|null|null|\n",
      "+--------------------+---------+----------+------------+--------------+-------+-------------+----+----+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "edges_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_times = pd.read_pickle('walking_edges.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'walking_times' as 'walking_times' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reverse edges:\n",
    "walking_times = (walking_times.withColumnRenamed('source', 'temp').withColumnRenamed('target', 'source').withColumnRenamed('temp', 'target'))\n",
    "\n",
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['walk_duration']}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-------------+\n",
      "|         target|         source|walk_duration|\n",
      "+---------------+---------------+-------------+\n",
      "|8503000:0:41/42|8503000:0:43/44|          7.0|\n",
      "|8503000:0:41/42|   8503000:0:14|          7.0|\n",
      "|8503000:0:41/42|   8503000:0:16|          7.0|\n",
      "+---------------+---------------+-------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "walking_times.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove dics from dijkstra time for the moment and make it return the mean and std as well because we need it to validate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edges_for_trip(edges_df, day_id, arrival_time):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    min_dep_time = arrival_time - 60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_time))\n",
    "    \n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time']),\n",
    "                                                                       'trip_id': r['trip_id'],\n",
    "                                                                       'mean': r['mean'],\n",
    "                                                                       'std': r['std']})).collect()\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, arrival_hour*60+arrival_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 nodes removed"
     ]
    }
   ],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)\n",
    "\n",
    "old_number_of_nodes = graph.number_of_nodes()\n",
    "# Remove unreachable nodes\n",
    "dists, paths = normal_dijkstra(graph, '8503000')\n",
    "not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "_ = graph.remove_nodes_from(list(not_reachable))\n",
    "print('{} nodes removed'.format(old_number_of_nodes - graph.number_of_nodes()))\n",
    "\n",
    "# Temp for problem of name's encoding\n",
    "import unicodedata\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'duration': 2.0, 'std': None, 'time': 643.0, 'trip_id': u'3.TA.1-231-j19-1.1.H', 'mean': None}, 1: {'duration': 2.0, 'std': None, 'time': 703.0, 'trip_id': u'5.TA.1-231-j19-1.1.H', 'mean': None}, 2: {'duration': 2.0, 'std': None, 'time': 673.0, 'trip_id': u'4.TA.1-231-j19-1.1.H', 'mean': None}, 3: {'duration': 2.0, 'std': None, 'time': 733.0, 'trip_id': u'68.TA.1-231-j19-1.9.H', 'mean': None}, 4: {'duration': 2.0, 'std': None, 'time': 721.0, 'trip_id': u'40.TA.1-231-j19-1.3.H', 'mean': None}}"
     ]
    }
   ],
   "source": [
    "# Check if reversed, should be non empty:\n",
    "graph.get_edge_data('8572602','8502553')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dijkstra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dijkstra_with_time(G, first_source, arrival_time, last_target, confidence=None, \n",
    "                       confidence_step=0.01, durations_dicts=None, paths=None, departure_time = None):\n",
    "    G = G.copy()\n",
    "    #departure_time = arrival_time - MAX_TRIP_DURATION*60\n",
    "    departure_time = departure_time\n",
    "    while True:\n",
    "        \"\"\"\n",
    "        # Update durations according to confidence\n",
    "        if confidence != None:\n",
    "            if durations_dicts == None:\n",
    "                raise ValueError('You must pass durations_dicts for the confidence.')\n",
    "            # Load dict with modifications\n",
    "            if confidence not in durations_dicts:\n",
    "                edge_and_data_tuple = zip(G.edges(keys=True), \n",
    "                              map(lambda x: x[2], G.edges(data=True)))\n",
    "                edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "                durations_dicts[confidence] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                                        data['std'], \n",
    "                                                                                                        confidence)\n",
    "                                                   if data['mean'] != None and data['std'] != None\n",
    "                                                   else data['duration']\n",
    "                                                  } for e, data in edge_and_data_tuple}\n",
    "            \n",
    "            # Update graph\n",
    "            nx.set_edge_attributes(G, durations_dicts[confidence])\n",
    "        \"\"\"\n",
    "        \n",
    "        if not G.is_directed():\n",
    "            raise ValueError('Input graph is not directed while it should be.')\n",
    "\n",
    "        G_succ = G.succ \n",
    "        \n",
    "        # paths stores the nodes in dijkstra's shortest path\n",
    "        paths = {first_source: [first_source]}\n",
    "        \n",
    "        # stores the edges in dijkstra's shortest path\n",
    "        e_paths = {first_source: []}\n",
    "        \n",
    "        # dictionary of final distances to nodes\n",
    "        dist = {}  \n",
    "        \n",
    "        # dictionnary of whether it's the first time a node is visited\n",
    "        seen = {first_source: departure_time}\n",
    "\n",
    "        # use heapq with (distance,label) tuples\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "        c = count()\n",
    "        fringe = []  \n",
    "        \n",
    "        # push the source as the first node on the heap\n",
    "        push(fringe, (departure_time, next(c), first_source))\n",
    "\n",
    "        # while heap not empty\n",
    "        while fringe:\n",
    "            \n",
    "            # take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "\n",
    "            # check if node has already been looked at and has a final shortest distance: \n",
    "            if source in dist:\n",
    "                continue  # already searched this node so go to another\n",
    "\n",
    "            # take the distance to the node from the heap \n",
    "            # source starts with distance = departure_time\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the source is the last_target. \n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:\n",
    "                    \n",
    "                    # Check if walking edge: \n",
    "                    # walking edges have a departure time of -1\n",
    "                    dep_time_edge = G.get_edge_data(source, target, edge_id)['time']\n",
    "                    \n",
    "                    if dep_time_edge == -1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        # set the departure time to the distance to that node as we can leave immediatly\n",
    "                        dep_time_edge = d\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = G.get_edge_data(source, target, edge_id)['trip_id']\n",
    "                        \n",
    "                    # take only edges that have a departure time bigger \n",
    "                    # than the time it takes to get to the node\n",
    "                    if dep_time_edge < dist[source]:\n",
    "                       # move on to next edge if it's earlier \n",
    "                        continue\n",
    "                        \n",
    "                    # Check if edge is feasible (also accoring to confidence)\n",
    "                    # Check if last edge taken was not a walking edge\n",
    "                    # Check if there is at least a path of length 1 to the source node \n",
    "                    # (e.g. that this node is not the original source)\n",
    "                    if len(e_paths[source]) >= 1 and not e_paths[source][-1][2]['walk']:\n",
    "                        last_edge_source, last_edge_target, last_edge_info = e_paths[source][-1]\n",
    "                        last_delay = compute_delay_uncertainty(last_edge_info['mean'], \n",
    "                                                                   last_edge_info['std'], \n",
    "                                                                   confidence)\n",
    "                        # If we make a transport-> walk change\n",
    "                        if walking_edge:\n",
    "                            # add delay to departure time of walk as we will leave later\n",
    "                            dep_time_edge += last_delay\n",
    "                        else:\n",
    "                            # If we make a transport->transport change, check if we have time to change\n",
    "                            # To change we need that the next connection leaves >= 2 min + delay of transport\n",
    "                            # If not we cannot take that edge\n",
    "                            if current_trip_id != last_edge_info['trip_id']\\\n",
    "                            and dep_time_edge < dist[source] + 2 + last_delay:\n",
    "                                continue\n",
    "\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = G.get_edge_data(source, target, edge_id)['duration']\n",
    "                    \n",
    "                    if duration_cost is None:\n",
    "                            raise ValueError('Edge without a duration.')\n",
    "\n",
    "                    # Add the weight to the current distance to a node\n",
    "                    current_dist = dep_time_edge + duration_cost\n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:',\n",
    "                                                     'negative weights?')\n",
    "\n",
    "                    # either node has been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    elif target not in seen or current_dist < seen[target]:\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "                            edge_dict = G.get_edge_data(source, target, edge_id)\n",
    "                            \n",
    "                            edge_dict['walk'] = walking_edge\n",
    "                            edge_dict['departure_time'] = dep_time_edge\n",
    "                            \n",
    "                            e_paths[target] = e_paths[source] + [(source, target, edge_dict)]\n",
    "\n",
    "\n",
    "        # If there is no path to the last_target:\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                         'departure_time', 'walk', 'no_change', 'mean_std_null','mean','std'])\n",
    "\n",
    "        \n",
    "        # Validation: \n",
    "        if confidence == None or validate_path(e_paths[last_target], confidence, G):\n",
    "            break\n",
    "        else:\n",
    "            # else increase confidence by a confidence step and start again: \n",
    "            confidence += confidence_step\n",
    "            \n",
    "    # Path validated\n",
    "    if paths is not None:\n",
    "        nodes_data = G.nodes(data=True)\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        best_path = e_paths[last_target]\n",
    "        departure_string = minute_to_string(best_path[0][2]['departure_time'])\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                                      first_source,\n",
    "                                                                                      nodes_data[last_target]['name'],\n",
    "                                                                                      last_target, \n",
    "                                                                                      dist[last_target] - departure_time,\n",
    "                                                                                      minute_to_string(departure_time)))\n",
    "        \n",
    "        # Construct best path's data structure\n",
    "        best_path_df = pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                          'departure_time', 'walk', 'no_change', 'mean_std_null', 'mean','std'])\n",
    "        last_edge_info = False\n",
    "        for source, target, edge_info in best_path:\n",
    "            no_change = ('trip_id' in edge_info                                   # We're in a transport\n",
    "                         and last_edge_info and 'trip_id' in last_edge_info       # and last edge also\n",
    "                         and last_edge_info['trip_id'] == edge_info['trip_id'])   # and same trip_id\n",
    "            mean_std_null = 'trip_id' in edge_info and 'mean' not in edge_info or 'std' not in edge_info\n",
    "            \n",
    "            if not mean_std_null:\n",
    "                mean = edge_info['mean']\n",
    "                std = edge_info['std']\n",
    "                if  edge_info['mean'] == None or  edge_info['std'] == None: \n",
    "                    mean = edge_info['duration']\n",
    "                    std = 0\n",
    "            if 'mean' not in edge_info or 'std' not in edge_info:\n",
    "                mean = edge_info['duration']\n",
    "                std = 0\n",
    "                \n",
    "            \n",
    "            current_path_dict = {'from': nodes_data[source]['name'],\n",
    "                                 'from_id': source, \n",
    "                                 'to': nodes_data[target]['name'], \n",
    "                                 'to_id': target, \n",
    "                                 'duration': edge_info['duration'], \n",
    "                                 'total_duration': dist[target] - departure_time,\n",
    "                                 'departure_time': minute_to_string(edge_info['departure_time']), \n",
    "                                 'walk':edge_info['walk'], \n",
    "                                 'no_change': no_change, \n",
    "                                 'mean_std_null': mean_std_null,\n",
    "                                'mean':mean,\n",
    "                                'std':std}\n",
    "            best_path_df = best_path_df.append(current_path_dict, ignore_index=True)\n",
    "            last_edge_info = edge_info\n",
    "        \n",
    "        with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "            print(best_path_df)\n",
    "        return best_path_df\n",
    "    raise ValueError('Should not be here')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dijkstra_reversed(G, first_source, arrival_time, last_target, confidence=None, \n",
    "                       confidence_step=0.01, durations_dicts=None):\n",
    "    G = G.copy()\n",
    "    departure_time = -arrival_time\n",
    "\n",
    "    # inverse direction \n",
    "    temp = first_source\n",
    "    first_source = last_target\n",
    "    last_target = temp\n",
    "        \n",
    "    if not G.is_directed():\n",
    "        raise ValueError('Input graph is not directed while it should be.')\n",
    "\n",
    "    G_succ = G.succ \n",
    "        \n",
    "    # paths stores the nodes in dijkstra's shortest path\n",
    "    paths = {first_source: [first_source]}\n",
    "    # stores the edges in dijkstra's shortest path\n",
    "    e_paths = {first_source: []}\n",
    "        \n",
    "    # dictionary of final distances to nodes\n",
    "    dist = {}  \n",
    "        \n",
    "    # dictionnary of whether it's the first time a node is visited\n",
    "    seen = {first_source: departure_time}\n",
    "\n",
    "    # use heapq with (distance,label) tuples\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    c = count()\n",
    "    fringe = []  \n",
    "        \n",
    "    # push the source as the first node on the heap\n",
    "    push(fringe, (departure_time, next(c), first_source))\n",
    "    # while heap not empty\n",
    "    while True:\n",
    "        while fringe:\n",
    "            # take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "\n",
    "             # check if node has already been looked at and has a final shortest distance: \n",
    "            if source in dist:\n",
    "                  continue  # already searched this node so go to another\n",
    "\n",
    "            # take the distance to the node from the heap \n",
    "            # source starts with distance = departure_time\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the source is the last_target. \n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:  \n",
    "                    # Check if walking edge: \n",
    "                    # walking edges have a departure time of -1\n",
    "                    dep_time_edge = - G.get_edge_data(source, target, edge_id)['time']\n",
    "\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = G.get_edge_data(source, target, edge_id)['duration']\n",
    "\n",
    "                    if dep_time_edge == 1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        # set the departure time to the \n",
    "                        # distance to that node as we can leave immediatly\n",
    "                        dep_time_edge = d + duration_cost                  \n",
    "\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = G.get_edge_data(source, target, edge_id)['trip_id']\n",
    "\n",
    "\n",
    "                    if duration_cost is None:\n",
    "                            raise ValueError('Edge without a duration.')\n",
    "\n",
    "                    # Add the weight to the current distance to a node\n",
    "\n",
    "                    current_dist = dep_time_edge           \n",
    "                    # take only edges that have a departure time bigger \n",
    "                    # than the time it takes to get to the node\n",
    "\n",
    "                    if dep_time_edge - duration_cost < dist[source]:\n",
    "                            # move on to next edge if it's earlier \n",
    "                        continue\n",
    "\n",
    "                    # Check if edge is feasible (also accoring to confidence)\n",
    "                    # Check if last edge taken was not a walking edge\n",
    "                    # Check if there is at least a path of length 1 to the source node \n",
    "                    # (e.g. that this node is not the original source)\n",
    "                    if len(e_paths[source]) >= 1 and not walking_edge:\n",
    "                        last_edge_source, last_edge_target, last_edge_info = e_paths[source][-1]\n",
    "                        mean = G.get_edge_data(source, target, edge_id)['mean']\n",
    "                        std = G.get_edge_data(source, target, edge_id)['std']\n",
    "                        # now compute delay for current edge because in reverse\n",
    "                        last_delay = compute_delay_uncertainty(mean, std, confidence)\n",
    "\n",
    "                        # If we make a transport-> walk change\n",
    "                        if last_edge_info['walk']:\n",
    "                            # add delay to departure time of walk as we will leave later\n",
    "                            dep_time_edge -= last_delay\n",
    "                        else:\n",
    "                            # If we make a transport->transport change, check if we have time to change\n",
    "                            # To change we need that the next connection leaves >= 2 min + delay of transport\n",
    "                            # If not we cannot take that edge\n",
    "                            #if current_trip_id != last_edge_info['trip_id']\\\n",
    "                            #and dep_time_edge < dist[source] + 2 + last_delay:\n",
    "                            #   continue\n",
    "                            if current_trip_id != last_edge_info['trip_id'] and dep_time_edge - last_delay - 2 - duration_cost < dist[source]:\n",
    "                                continue                \n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:','negative weights?')\n",
    "\n",
    "                    # either node has been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    if target not in seen or current_dist < seen[target]:\n",
    "\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "\n",
    "                            edge_dict = G.get_edge_data(source, target, edge_id)\n",
    "\n",
    "                            edge_dict['walk'] = walking_edge\n",
    "                            edge_dict['departure_time'] = dep_time_edge\n",
    "                            e_paths[target] = e_paths[source] + [(source, target, edge_dict)]    \n",
    "        \n",
    "        # If there is no path to the last_target:\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                             'departure_time', 'walk', 'no_change', 'mean_std_null','mean','std'])\n",
    "\n",
    "\n",
    "        # Validation: \n",
    "        if confidence == None or validate_path(e_paths[last_target], confidence, G):\n",
    "            break\n",
    "        else:\n",
    "            # else increase confidence by a confidence step and start again: \n",
    "            confidence += confidence_step\n",
    "        # Path validated\n",
    "    if paths is not None:\n",
    "        nodes_data = G.nodes(data=True)\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        \n",
    "        #reverse path:\n",
    "        best_path = []\n",
    "        for edge in e_paths[last_target][::-1]: \n",
    "            edge = (edge[1], edge[0], edge[2])\n",
    "            best_path.append(edge)           \n",
    "        \n",
    "        departure_string = minute_to_string(-best_path[0][2]['departure_time'])\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                                      first_source,\n",
    "                                                                                      nodes_data[last_target]['name'],\n",
    "                                                                                      last_target, \n",
    "                                                                                      arrival_time + best_path[0][2]['departure_time'] ,\n",
    "                                                                                      minute_to_string(-best_path[0][2]['departure_time'])))\n",
    "        \n",
    "        # Construct best path's data structure\n",
    "        best_path_df = pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                          'departure_time', 'walk', 'no_change', 'mean_std_null', 'mean','std'])\n",
    "        last_edge_info = False\n",
    "        for source, target, edge_info in best_path:\n",
    "            no_change = ('trip_id' in edge_info                                   # We're in a transport\n",
    "                         and last_edge_info and 'trip_id' in last_edge_info       # and last edge also\n",
    "                         and last_edge_info['trip_id'] == edge_info['trip_id'])   # and same trip_id\n",
    "            mean_std_null = 'trip_id' in edge_info and 'mean' not in edge_info or 'std' not in edge_info\n",
    "            \n",
    "            if not mean_std_null:\n",
    "                mean = edge_info['mean']\n",
    "                std = edge_info['std']\n",
    "                if  edge_info['mean'] == None or  edge_info['std'] == None: \n",
    "                    mean = edge_info['duration']\n",
    "                    std = 0\n",
    "            if 'mean' not in edge_info or 'std' not in edge_info:\n",
    "                mean = edge_info['duration']\n",
    "                std = 0\n",
    "                \n",
    "            \n",
    "            current_path_dict = {'from': nodes_data[source]['name'],\n",
    "                                 'from_id': source, \n",
    "                                 'to': nodes_data[target]['name'], \n",
    "                                 'to_id': target, \n",
    "                                 'duration': edge_info['duration'], \n",
    "                                 'total_duration': dist[target],\n",
    "                                 'departure_time': minute_to_string(-edge_info['departure_time']), \n",
    "                                 'walk':edge_info['walk'], \n",
    "                                 'no_change': no_change, \n",
    "                                 'mean_std_null': mean_std_null,\n",
    "                                'mean':mean,\n",
    "                                'std':std}\n",
    "            best_path_df = best_path_df.append(current_path_dict, ignore_index=True)\n",
    "            last_edge_info = edge_info\n",
    "        \n",
    "        #with pd.option_context('display.max_rows', None, \n",
    "        #                       'display.max_columns', None, \n",
    "        #                       'display.max_colwidth', 15,\n",
    "        #                       'display.expand_frame_repr', False):\n",
    "        #        print(best_path_df)\n",
    "        return best_path_df\n",
    "    raise ValueError('Should not be here')\n",
    "    return e_paths[last_target], dist[last_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "Going from Zurich Oerlikon (8503006:0:2) to Zurich Oerlikon (8503006:0:8) in 3.00 minutes, departure at 12:27\n",
      "             from      from_id              to        to_id  duration total_duration departure_time  walk no_change mean_std_null  mean std\n",
      "0  Zurich Oerl...  8503006:0:8  Zurich Oerl...  8503006:0:2       3.0           -750          12:27  True     False          True   3.0   0"
     ]
    }
   ],
   "source": [
    "source = '8503006:0:8'\n",
    "target = '8503006:0:2'\n",
    "\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "print(arrival_hour*60+arrival_minute)\n",
    "path = dijkstra_reversed(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "Going from Zurich, Auzelg (8591049) to Zurich HB (8503000) in 25.14 minutes, departure at 12:04\n",
      "             from         from_id              to           to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB         8503000       Zurich HB  8503000:0:4...  2.135259       23.000000          12:04   True     False          True  2.135259        0\n",
      "1       Zurich HB  8503000:0:4...  Zurich Hard...     8503020:0:3  2.000000       21.000000          12:07  False     False         False  0.336499  1.09469\n",
      "2  Zurich Hard...     8503020:0:3  Zurich Oerl...     8503006:0:8  5.000000       15.000000          12:09  False      True         False  5.000000        0\n",
      "3  Zurich Oerl...     8503006:0:8      Glattbrugg     8503310:0:3  2.000000       10.063448          12:15  False      True         False  2.000000        0\n",
      "4      Glattbrugg     8503310:0:3  Glattbrugg,...         8590620  3.063448        7.000000          12:19   True     False          True  3.063448        0\n",
      "5  Glattbrugg,...         8590620  Glattbrugg,...         8590626  1.000000        6.000000          12:23  False     False         False  0.639793  1.40383\n",
      "6  Glattbrugg,...         8590626  Glattpark, ...         8591830  2.000000        4.000000          12:24  False      True         False  0.829374  1.32294\n",
      "7  Glattpark, ...         8591830  Zurich, Fer...         8591128  1.000000        3.000000          12:26  False      True         False  0.891561   1.4187\n",
      "8  Zurich, Fer...         8591128  Zurich, Auzelg         8591049  2.000000        0.000000          12:27  False      True         False  0.956600  1.35904"
     ]
    }
   ],
   "source": [
    "source = '8503000'\n",
    "target = '8591049'\n",
    "\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "print(arrival_hour*60+arrival_minute)\n",
    "path = dijkstra_reversed(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "    print(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrival time 750\n",
      "-750\n",
      "('8582462', '8572602')\n",
      "('8572602', '8582462')\n",
      "Source was last target\n",
      "([('8572602', '8502553', {'std': 0, 'walk': False, 'time': 583.0, 'duration': 2.0, 'trip_id': '1.TA.1-231-j19-1.1.H', 'departure_time': -583.0, 'mean': 0}), ('8502553', '8582462', {'std': 0, 'walk': False, 'time': 578.0, 'duration': 2.0, 'trip_id': '1.TA.1-231-j19-1.2.H', 'departure_time': -578.0, 'mean': 0})], -578.0)"
     ]
    }
   ],
   "source": [
    "source = '8582462'\n",
    "target = '8572602'\n",
    "\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "print('Arrival time {}'.format(arrival_hour*60+arrival_minute))\n",
    "\n",
    "path = dijkstra_reversed(mini_graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]"
     ]
    }
   ],
   "source": [
    "from geopy.distance import distance as geo_distance\n",
    "import networkx as nx\n",
    "from geopy.distance import distance as geo_distance\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType\n",
    "from networkx.algorithms.shortest_paths.weighted import dijkstra_path\n",
    "\n",
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "\n",
    "def zurich_distance(x, y):\n",
    "    \"\"\"zurich_distance: returns the distance of a station to Zurich HB\n",
    "    @input: (lat,lon) of a station\n",
    "    @output: distance in km to Zurich HB\n",
    "    \"\"\"\n",
    "    return geo_distance(47.3781762039461, 8.54019357578468, (x,y)).km\n",
    "\n",
    "# Filter stop_times to be only in 08:00-19:59:\n",
    "stop_times = stop_times.where((col('departure_time') >= '08:00:00') \n",
    "                              & (col('departure_time') <= '19:59:59'))\n",
    "\n",
    "# filter stops:\n",
    "stops_distance = stops.rdd.map(lambda x: (x['stop_id'], zurich_distance(x['stop_lat'], x['stop_lon'])))\n",
    "stops_distance = spark.createDataFrame(stops_distance.map(lambda r: Row(stop_id=r[0], \n",
    "                                                                        zurich_distance=r[1])))\n",
    "\n",
    "stops_distance = stops_distance.filter(col('zurich_distance') <= 15)\n",
    "\n",
    "# add distance to HB to stops info and keep only in radius of 15km\n",
    "stops_zurich = stops_distance.join(stops, on='stop_id')\n",
    "\n",
    "# keep only stop times in radius of 15km of Zurich\n",
    "stop_times_zurich = stop_times.join(stops_distance.select('stop_id'), on='stop_id')\n",
    "\n",
    "## create a simple graph: \n",
    "trip_id = '1.TA.1-231-j19-1.1.H'\n",
    "\n",
    "#select four stops : \n",
    "stops_minig = ['8582462','8572600','8572601','8502553']\n",
    "\n",
    "stop_times_info = stop_times_zurich.where((col('stop_id').isin(stops_minig))&(col('trip_id') == trip_id))\n",
    "\n",
    "stops_info = stops_zurich.where(col('stop_id').isin(stops_minig))\n",
    "\n",
    "\n",
    "mini_graph = nx.MultiDiGraph()\n",
    "\n",
    "mini_nodes = stops_info.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()\n",
    "mini_graph.add_nodes_from(mini_nodes)\n",
    "\n",
    "\n",
    "# add artificial edge: \n",
    "mini_graph.add_edges_from([('8572600',  '8582462', {'duration': 2.0, 'time': 578.0, 'trip_id':  '1.TA.1-231-j19-1.1.H', 'mean':0, 'std':0}), \n",
    "                          ('8572600',  '8582462', {'duration': 1.0, 'time': 578.0, 'trip_id':  '1.TA.1-231-j19-1.1.H', 'mean':0, 'std':0}),\n",
    "                          ( '8572601',  '8572600',{'duration': 0.0, 'time': 579.0, 'trip_id':  '1.TA.1-231-j19-1.1.H', 'mean':0, 'std':0}),\n",
    "                          ( '8502553',  '8572601',{'duration': 4.0, 'time': 579.0, 'trip_id':  '1.TA.1-231-j19-1.1.H', 'mean':0, 'std':0}),\n",
    "                          ( '8572602',  '8502553',{'duration': 2.0, 'time': 583.0, 'trip_id':  '1.TA.1-231-j19-1.1.H', 'mean':0, 'std':0}),])\n",
    "\n",
    "mini_graph.add_edges_from([('8502553',  '8582462', {'duration': 2.0, 'time': 578.0, 'trip_id':  '1.TA.1-231-j19-1.2.H', 'mean':0, 'std':0})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrival time 750\n",
      "Going from Zurich, Auzelg (8591049) to Zurich HB (8503000) in 25.14 minutes, departure at 12:04\n",
      "                         from          from_id  ...      mean      std\n",
      "0                   Zurich HB          8503000  ...  2.135259        0\n",
      "1                   Zurich HB  8503000:0:41/42  ...  0.336499  1.09469\n",
      "2           Zurich Hardbrucke      8503020:0:3  ...  5.000000        0\n",
      "3             Zurich Oerlikon      8503006:0:8  ...  2.000000        0\n",
      "4                  Glattbrugg      8503310:0:3  ...  3.063448        0\n",
      "5         Glattbrugg, Bahnhof          8590620  ...  0.639793  1.40383\n",
      "6  Glattbrugg, Lindberghplatz          8590626  ...  0.829374  1.32294\n",
      "7        Glattpark, Glattpark          8591830  ...  0.891561   1.4187\n",
      "8       Zurich, Fernsehstudio          8591128  ...  0.956600  1.35904\n",
      "\n",
      "[9 rows x 12 columns]"
     ]
    }
   ],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "print('Arrival time {}'.format(arrival_hour*60+arrival_minute))\n",
    "\n",
    "path = dijkstra_reversed(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049',\n",
    "                                confidence = 0.98)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049) in 47.47 minutes, departure at 11:57\n",
      "             from       from_id              to         to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean      std\n",
      "0       Zurich HB       8503000       Zurich HB  8503000:0:31   4.164130        4.164130          11:57   True     False          True   4.164130        0\n",
      "1       Zurich HB  8503000:0:31  Zurich Oerl...   8503006:0:3   5.000000       10.000000          12:02  False     False         False   5.000000        0\n",
      "2  Zurich Oerl...   8503006:0:3  Zurich Oerl...       8591063   5.930877       15.930877          12:07   True     False          True   5.930877        0\n",
      "3  Zurich Oerl...       8591063  Zurich, Leu...       8591256   2.000000       18.000000          12:13  False     False         False   1.405997  2.92055\n",
      "4  Zurich, Leu...       8591256  Zurich, Hag...       8591172   1.000000       22.000000          12:18  False     False         False   1.422793  2.27707\n",
      "5  Zurich, Hag...       8591172  Zurich, Rie...       8591318   1.000000       27.000000          12:23  False     False         False   1.355124  2.27176\n",
      "6  Zurich, Rie...       8591318  Zurich, Gen...       8591225   8.519710       36.197559          12:24   True     False          True   8.519710        0\n",
      "7  Zurich, Gen...       8591225  Zurich, Auzelg       8591049  11.274905       47.472464          12:33   True     False          True  11.274905        0\n",
      "             from       from_id              to         to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean      std\n",
      "0       Zurich HB       8503000       Zurich HB  8503000:0:31   4.164130        4.164130          11:57   True     False          True   4.164130        0\n",
      "1       Zurich HB  8503000:0:31  Zurich Oerl...   8503006:0:3   5.000000       10.000000          12:02  False     False         False   5.000000        0\n",
      "2  Zurich Oerl...   8503006:0:3  Zurich Oerl...       8591063   5.930877       15.930877          12:07   True     False          True   5.930877        0\n",
      "3  Zurich Oerl...       8591063  Zurich, Leu...       8591256   2.000000       18.000000          12:13  False     False         False   1.405997  2.92055\n",
      "4  Zurich, Leu...       8591256  Zurich, Hag...       8591172   1.000000       22.000000          12:18  False     False         False   1.422793  2.27707\n",
      "5  Zurich, Hag...       8591172  Zurich, Rie...       8591318   1.000000       27.000000          12:23  False     False         False   1.355124  2.27176\n",
      "6  Zurich, Rie...       8591318  Zurich, Gen...       8591225   8.519710       36.197559          12:24   True     False          True   8.519710        0\n",
      "7  Zurich, Gen...       8591225  Zurich, Auzelg       8591049  11.274905       47.472464          12:33   True     False          True  11.274905        0"
     ]
    }
   ],
   "source": [
    "best_path1 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049',\n",
    "                                confidence = 0.98, departure_time = 717.0)\n",
    "with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "    print(best_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057) in 52.36 minutes, departure at 11:57\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean       std\n",
      "0  Zurich, Tri...  8503610  Zurich, Sch...  8580912   1.000000        3.000000          11:59  False     False         False   0.788371  1.243114\n",
      "1  Zurich, Sch...  8580912  Zurich, Im Gut  8591208   1.000000        6.000000          12:02  False     False         False   1.400469  1.407420\n",
      "2  Zurich, Im Gut  8591208  Zurich, Hub...  8591203   1.000000       12.000000          12:08  False     False         False   1.388227  1.704782\n",
      "3  Zurich, Hub...  8591203  Zurich, Alb...  8591035   2.000000       19.000000          12:14  False     False         False   1.843465  1.595908\n",
      "4  Zurich, Alb...  8591035  Zurich, Flu...  8591134   1.000000       25.000000          12:21  False     False         False   1.769857  1.581397\n",
      "5  Zurich, Flu...  8591134  Zurich, Kap...  8591222   1.000000       31.000000          12:27  False     False         False   1.705416  1.657151\n",
      "6  Zurich, Kap...  8591222  Zurich, Lug...  8591265  11.302652       42.302652          12:28   True     False          True  11.302652  0.000000\n",
      "7  Zurich, Lug...  8591265  Zurich Alts...  8591057  10.056910       52.359562          12:39   True     False          True  10.056910  0.000000\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean       std\n",
      "0  Zurich, Tri...  8503610  Zurich, Sch...  8580912   1.000000        3.000000          11:59  False     False         False   0.788371  1.243114\n",
      "1  Zurich, Sch...  8580912  Zurich, Im Gut  8591208   1.000000        6.000000          12:02  False     False         False   1.400469  1.407420\n",
      "2  Zurich, Im Gut  8591208  Zurich, Hub...  8591203   1.000000       12.000000          12:08  False     False         False   1.388227  1.704782\n",
      "3  Zurich, Hub...  8591203  Zurich, Alb...  8591035   2.000000       19.000000          12:14  False     False         False   1.843465  1.595908\n",
      "4  Zurich, Alb...  8591035  Zurich, Flu...  8591134   1.000000       25.000000          12:21  False     False         False   1.769857  1.581397\n",
      "5  Zurich, Flu...  8591134  Zurich, Kap...  8591222   1.000000       31.000000          12:27  False     False         False   1.705416  1.657151\n",
      "6  Zurich, Kap...  8591222  Zurich, Lug...  8591265  11.302652       42.302652          12:28   True     False          True  11.302652  0.000000\n",
      "7  Zurich, Lug...  8591265  Zurich Alts...  8591057  10.056910       52.359562          12:39   True     False          True  10.056910  0.000000"
     ]
    }
   ],
   "source": [
    "best_path2 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057', departure_time = 717.0)\n",
    "with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "    print(best_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrival time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convertToMinute(s):\n",
    "    h, m = s.split(':')\n",
    "    h,m = int(h), int(m)\n",
    "    \n",
    "    return h*60+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decrements = [10, 5, 2, 1, 0]\n",
    "source = '8503000'\n",
    "target = '8591122'\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "\n",
    "arrival_time = arrival_hour*60+arrival_minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 27.00 minutes, departure at 10:30\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          10:30   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       27.000000          10:44  False     False         False  1.210631  1.28324\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 34.00 minutes, departure at 11:53\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:53   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       34.000000          12:14  False     False         False  1.182748  1.58472\n",
      "Start with 3.0 minutes difference\n",
      "Trip takes 34.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 36.00 minutes, departure at 11:51\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:51   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       36.000000          12:14  False     False         False  1.182748  1.58472\n",
      "Start with 3.0 minutes difference\n",
      "Trip takes 36.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 35.00 minutes, departure at 11:52\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:52   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       35.000000          12:14  False     False         False  1.182748  1.58472\n",
      "Start with 3.0 minutes difference\n",
      "Trip takes 35.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 33.00 minutes, departure at 11:54\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:54   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       33.000000          12:14  False     False         False  1.182748  1.58472\n",
      "Start with 3.0 minutes difference\n",
      "Trip takes 33.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 30.00 minutes, departure at 11:57\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:57   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       30.000000          12:14  False     False         False  1.182748  1.58472\n",
      "Start with 3.0 minutes difference\n",
      "Trip takes 30.0 minutes\n",
      "717.0"
     ]
    }
   ],
   "source": [
    "decrements = [10, 5, 2, 1, 0]\n",
    "source = '8503000'\n",
    "target = '8591122'\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "\n",
    "arrival_time = arrival_hour*60+arrival_minute\n",
    "\n",
    "def depart_time(arrival_time, source, target, decrements):\n",
    "    #start with two hours before:\n",
    "    dep = arrival_time - MAX_TRIP_DURATION*60\n",
    "    path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = dep)\n",
    "    num_edges = len(path['total_duration'])\n",
    "    duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "    first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "    arrival_diff = arrival_time - first_arrival\n",
    "    \n",
    "    departures = [dep]\n",
    "    \n",
    "    if arrival_diff < 0:\n",
    "        raise ErrorValue('Arrives after wanted arrival time')\n",
    "    for i in decrements:\n",
    "        dep = arrival_time - duration - i\n",
    "        path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = dep)\n",
    "        num_edges = len(path['total_duration'])\n",
    "        duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "        first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "        arrival_diff = arrival_time - first_arrival\n",
    "        \n",
    "        if arrival_diff < 0:\n",
    "            return departures[0]\n",
    "        \n",
    "        departures.insert(0, dep)\n",
    "\n",
    "        print('Start with {} minutes difference'.format(arrival_diff))\n",
    "        print('Trip takes {} minutes'.format(duration))\n",
    "\n",
    "        \n",
    "    return departures[0]\n",
    "\n",
    "dep = depart_time(arrival_time, source, target, decrements)\n",
    "dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 30.00 minutes, departure at 11:57\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:57   True     False          True  9.300864        0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  13.000000       30.000000          12:14  False     False         False  1.182748  1.58472\n",
      "                from  from_id  ...      mean      std\n",
      "0          Zurich HB  8503000  ...  9.300864        0\n",
      "1  Zurich, Haldenegg  8591174  ...  1.182748  1.58472\n",
      "\n",
      "[2 rows x 12 columns]"
     ]
    }
   ],
   "source": [
    "dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = 717.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation:\n",
    "\n",
    "##### Feasible paths:\n",
    "Create a function that looks through a path to see if it is valid. \n",
    "So it looks for:\n",
    "- missed connections\n",
    "- transfer time of less than 2 minutes between two transports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Returns true if there is time to take all edges, and if \n",
    "when chaning from a connection to another you have at least 2 minutes. \"\"\"\n",
    "\n",
    "def is_path_valid(path):\n",
    "    last_target = path['from_id'][len(path['from_id'])-1]\n",
    "    time = convertToMinute(path['departure_time'][0]) + path['duration'][0]\n",
    "    \n",
    "    for i in range(1, len(path['from_id'])):\n",
    "        #in case an edge taken actually left before we got there (only for transport edges, not for walks)\n",
    "        if not path['walk'][i] and convertToMinute(path['departure_time'][i]) < time:\n",
    "            print('You miss this connection. Time is {} while this edge leaves at {} from {} to {}'\\\n",
    "                  .format(minute_to_string(time), path['departure_time'][i], path['from'][i], path['to'][i]))\n",
    "            return False\n",
    "        \n",
    "        #in case of change type transport -> trasnport need 2 minutes transfer:\n",
    "        if not path['no_change'][i] and not path['walk'][i]:\n",
    "            if not path['walk'][i-1]:\n",
    "                if convertToMinute(path['departure_time'][i]) < time + 2:\n",
    "                    print('You do not have time to change to this connection between {} to {} leaving at {}. You arrive at {} and need at least 2 min transfer'\\\n",
    "                          .format(path['from'][i],path['to'][i], path['departure_time'][i], minute_to_string(time)))\n",
    "                    return False\n",
    "        \n",
    "        else: \n",
    "            time = convertToMinute(path['departure_time'][i]) + path['duration'][i]\n",
    "    return True\n",
    "\n",
    "# test of is path valid:\n",
    "#assert(is_path_valid(best_path1))\n",
    "#assert(is_path_valid(best_path2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate a path:\n",
    "Then for a given path, we sample felays for transfers where we go from a transport -> walk or transport -> transport. \n",
    "\n",
    "For transport 1 -> transport 2: the delay of transport 1 will be added to its trip duration\n",
    "For transport -> walk: the delay of transport will be added to the departure time of walk \n",
    "\n",
    "After modifying these values, we check whether the path is still feasible. We repeat this operation a ceertain number of times and report the percentage of feasible paths. \n",
    "\n",
    "For the moment, delays are sampled from an absolute normal distribution (**?good?**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_path_(path, confidence):\n",
    "    num_tries = 10\n",
    "    num_valids = 0\n",
    "    \n",
    "    for i in range(num_tries):\n",
    "        path_copy = path.copy()\n",
    "        for i in range(len(path['from_id'])):\n",
    "            #only for transfers etiher to other trains or to walking: \n",
    "            if i > 1 and not path['no_change'][i]:\n",
    "                mean = path['mean'][i-1]\n",
    "                std = path['std'][i-1]\n",
    "                #sample a delay:\n",
    "                #delay = compute_delay_uncertainty(mean, std, confidence)\n",
    "                \n",
    "                # calcluate delay for connection of before:\n",
    "                if std != 0:\n",
    "                    \n",
    "                    delay = np.random.normal(mean, std)\n",
    "                    if delay <0:\n",
    "                        delay = 0\n",
    "                else: delay = 0\n",
    "                \n",
    "                # if its between two transports we just add it to trip duration:\n",
    "                if not path['walk'][i] and not path['walk'][i-1]:\n",
    "                    print('Delay of {} for {} to {}'.format(delay, path_copy['from'][i-1], path_copy['to'][i-1]))\n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                \n",
    "                # transfer from trans to walk:\n",
    "                if not path['walk'][i-1] and path['walk'][i]:\n",
    "                    # if a train to a walk is delayed, the walk needs to leave later:\n",
    "                    #need to leave at the time it takes for the delayed connection to arrive, \n",
    "                    # so if delayed need to start walking later: \n",
    "                    \n",
    "                    if delay !=0:\n",
    "                        print('Delay of {} for {} to {}, need to start walking later from {}'\\\n",
    "                                  .format(delay, path_copy['from'][i-1], path_copy['to'][i-1], path_copy['to'][i-1]))\n",
    "                    \n",
    "                    #add duration to transp: \n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                    \n",
    "                    #delay the start of walk:\n",
    "                    arrival_of_edge_before = path_copy['duration'][i-1]+convertToMinute(path_copy['departure_time'][i-1])\n",
    "                    \n",
    "                    # need to start later:\n",
    "                    new_dep_time = minute_to_string(arrival_of_edge_before)\n",
    "                    path_copy['departure_time'][i] = new_dep_time\n",
    "        \n",
    "        if is_path_valid(path_copy):\n",
    "            num_valids += 1\n",
    "    return num_valids/float(num_tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "name 'durations_dicts' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'durations_dicts' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test pour voir si on peut rater une connection: \n",
    "test = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591122', confidence=0.98, durations_dicts=durations_dicts)\n",
    "test['mean'][10] = 6\n",
    "test['std'][10] = 4\n",
    "validate_path_(test, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create duration dictionnaries if needed\n",
    "\n",
    "Code commented, don't have the permission to **change** a file, can write if put another path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durations_dicts = {}\n",
    "edge_and_data_tuple = zip(graph.edges(keys=True),\n",
    "              map(lambda x: x[2], graph.edges(data=True)))\n",
    "edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "for c in [0.25, 0.5, 0.75, 0.9, 0.95, 0.98, 0.99]:\n",
    "    durations_dicts[c] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                            data['std'], \n",
    "                                                                                            c)\n",
    "                                       if data['mean'] != None and data['std'] != None\n",
    "                                       else data['duration']\n",
    "                                      } for e, data in edge_and_data_tuple}\n",
    "    \n",
    "\"\"\" Conversion to json \"\"\"\n",
    "durations_dicts_for_json = {}\n",
    "for c in durations_dicts.keys():\n",
    "    durations_dicts_for_json[c] = {str(k): v for k, v in durations_dicts[c].items()}\n",
    "\n",
    "print('Length of json:', len(json.dumps(durations_dicts_for_json))) -> 30106955\n",
    "\n",
    "\"\"\" Save to hdfs \"\"\"\n",
    "sc.parallelize([json.dumps(durations_dicts_for_json)]).coalesce(1).saveAsTextFile('/user/{}/durations_for_confidence_.json'.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without minimum confidence ->\n",
      "\n",
      "With minimum confidence ->"
     ]
    }
   ],
   "source": [
    "# Tao's example (except for the departure time)\n",
    "print('Without minimum confidence ->')\n",
    "#best_path1 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049',confidence = 0.98, durations_dicts=durations_dicts)\n",
    "print('\\nWith minimum confidence ->')\n",
    "#best_path2 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049', confidence=0.98, durations_dicts=durations_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without minimum confidence ->\n",
      "\n",
      "With minimum confidence ->"
     ]
    }
   ],
   "source": [
    "# From Triemli to Altstetten\n",
    "print('Without minimum confidence ->')\n",
    "#best_path1 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057')\n",
    "print('\\nWith minimum confidence ->')\n",
    "#best_path2 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057', confidence=0.95, durations_dicts=durations_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None"
     ]
    }
   ],
   "source": [
    "# Weird attributes?\n",
    "print(graph.get_edge_data('8503000:0:41/42', '8503020:0:3', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046632828786368166"
     ]
    }
   ],
   "source": [
    "# Proportion of null mean or std in non-walking edges\n",
    "(len(filter(lambda x: x[2]['mean'] == None or x[2]['std'] == None, filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True))))\n",
    " / float(len(filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
