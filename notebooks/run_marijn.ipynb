{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run:\n",
    "Only notebook to run ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'pyFiles': ['/user/gottraux/dijkstra_algorithms.py'], 'conf': {'spark.app.name': 'dslab-group_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8875</td><td>application_1589299642358_3407</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3407/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3407_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8901</td><td>application_1589299642358_3433</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3433/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3433_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8907</td><td>application_1589299642358_3439</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3439/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3439_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8919</td><td>application_1589299642358_3451</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3451/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3451_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8922</td><td>application_1589299642358_3454</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3454/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3454_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8923</td><td>application_1589299642358_3455</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3455/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3455_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8924</td><td>application_1589299642358_3456</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3456/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3456_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8925</td><td>application_1589299642358_3457</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3457/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3457_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8926</td><td>application_1589299642358_3458</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3458/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3458_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8927</td><td>application_1589299642358_3459</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3459/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3459_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8931</td><td>application_1589299642358_3463</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3463/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3463_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8932</td><td>application_1589299642358_3464</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3464/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3464_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8933</td><td>application_1589299642358_3465</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3465/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3465_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8934</td><td>application_1589299642358_3466</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3466/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3466_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8935</td><td>application_1589299642358_3467</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3467/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3467_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8936</td><td>application_1589299642358_3468</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3468/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3468_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8939</td><td>application_1589299642358_3471</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3471/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3471_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8941</td><td>application_1589299642358_3473</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3473/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3473_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8942</td><td>application_1589299642358_3474</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3474/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3474_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8944</td><td>application_1589299642358_3476</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3476/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3476_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8945</td><td>application_1589299642358_3477</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3477/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3477_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8946</td><td>application_1589299642358_3478</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3478/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3478_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8947</td><td>application_1589299642358_3479</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3479/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3479_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8948</td><td>application_1589299642358_3480</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3480/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3480_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8949</td><td>application_1589299642358_3481</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3481/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3481_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8952</td><td>application_1589299642358_3484</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3484/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3484_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8953</td><td>application_1589299642358_3485</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3485/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3485_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8954</td><td>application_1589299642358_3486</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3486/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3486_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8956</td><td>application_1589299642358_3488</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3488/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3488_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"pyFiles\": [\"/user/gottraux/dijkstra_algorithms.py\"],\n",
    " \"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8957</td><td>application_1589299642358_3489</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3489/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3489_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\"\"\"\n",
    "To load (or reload) into hdfs:\n",
    "hdfs dfs -rm /user/${JUPYTERHUB_USER}/dijkstra_algorithms.py 2>/dev/null\n",
    "hdfs dfs -copyFromLocal notebooks/dijkstra_algorithms.py /user/${JUPYTERHUB_USER}/\n",
    "\"\"\"\n",
    "from dijkstra_algorithms import *\n",
    "\n",
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import pandas as pd\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "#username = 'gottraux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convertToMinute(s):\n",
    "    h, m = s.split(':')\n",
    "    h,m = int(h), int(m)\n",
    "    \n",
    "    return h*60+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "stop_times = spark.read.format('orc').load('/data/sbb/timetables/orc/stop_times/000000_0')\n",
    "stops = spark.read.format('orc').load('/data/sbb/timetables/orc/stops/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges_with_mean_and_std_sec.orc\".format(username))\n",
    "\n",
    "#durations_dicts = json.loads(sc.textFile('/user/{}/durations_for_confidence_.json'.format(username)).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+------------+--------------+---------+-------------+----+----+\n",
      "|             trip_id|stop_id|train_type|arrival_time|departure_time|next_stop|trip_duration|mean| std|\n",
      "+--------------------+-------+----------+------------+--------------+---------+-------------+----+----+\n",
      "|30.TA.30-24-Y-j19...|8503111|       Bus|         496|           496|  8503102|          4.0|null|null|\n",
      "|34.TA.30-24-Y-j19...|8503111|       Bus|         539|           539|  8503102|          4.0|null|null|\n",
      "|31.TA.30-31-Y-j19...|8503111|       Bus|         532|           532|  8503103|          5.0|null|null|\n",
      "+--------------------+-------+----------+------------+--------------+---------+-------------+----+----+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "edges_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges_df = edges_df.withColumnRenamed('stop_id', 'temp').withColumnRenamed('next_stop', 'stop_id').withColumnRenamed('temp', 'next_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+------------+--------------+-------+-------------+----+----+\n",
      "|             trip_id|next_stop|train_type|arrival_time|departure_time|stop_id|trip_duration|mean| std|\n",
      "+--------------------+---------+----------+------------+--------------+-------+-------------+----+----+\n",
      "|30.TA.30-24-Y-j19...|  8503111|       Bus|         496|           496|8503102|          4.0|null|null|\n",
      "|34.TA.30-24-Y-j19...|  8503111|       Bus|         539|           539|8503102|          4.0|null|null|\n",
      "|31.TA.30-31-Y-j19...|  8503111|       Bus|         532|           532|8503103|          5.0|null|null|\n",
      "+--------------------+---------+----------+------------+--------------+-------+-------------+----+----+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "edges_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_times = pd.read_pickle('walking_edges.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'walking_times' as 'walking_times' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reverse edges:\n",
    "walking_times = (walking_times.withColumnRenamed('source', 'temp').withColumnRenamed('target', 'source').withColumnRenamed('temp', 'target'))\n",
    "\n",
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['walk_duration']}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-------------+\n",
      "|         target|         source|walk_duration|\n",
      "+---------------+---------------+-------------+\n",
      "|8503000:0:41/42|8503000:0:43/44|          7.0|\n",
      "|8503000:0:41/42|   8503000:0:14|          7.0|\n",
      "|8503000:0:41/42|   8503000:0:16|          7.0|\n",
      "+---------------+---------------+-------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "walking_times.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove dics from dijkstra time for the moment and make it return the mean and std as well because we need it to validate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edges_for_trip(edges_df, day_id, arrival_time):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    min_dep_time = arrival_time - 60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_time))\n",
    "    \n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time']),\n",
    "                                                                       'trip_id': r['trip_id'],\n",
    "                                                                       'mean': r['mean'],\n",
    "                                                                       'std': r['std']})).collect()\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, arrival_hour*60+arrival_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 nodes removed"
     ]
    }
   ],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)\n",
    "\n",
    "old_number_of_nodes = graph.number_of_nodes()\n",
    "# Remove unreachable nodes\n",
    "dists, paths = normal_dijkstra(graph, '8503000')\n",
    "not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "_ = graph.remove_nodes_from(list(not_reachable))\n",
    "print('{} nodes removed'.format(old_number_of_nodes - graph.number_of_nodes()))\n",
    "\n",
    "# Temp for problem of name's encoding\n",
    "import unicodedata\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'duration': 2.0, 'std': None, 'time': 643.0, 'trip_id': u'3.TA.1-231-j19-1.1.H', 'mean': None}, 1: {'duration': 2.0, 'std': None, 'time': 703.0, 'trip_id': u'5.TA.1-231-j19-1.1.H', 'mean': None}, 2: {'duration': 2.0, 'std': None, 'time': 673.0, 'trip_id': u'4.TA.1-231-j19-1.1.H', 'mean': None}, 3: {'duration': 2.0, 'std': None, 'time': 733.0, 'trip_id': u'68.TA.1-231-j19-1.9.H', 'mean': None}, 4: {'duration': 2.0, 'std': None, 'time': 721.0, 'trip_id': u'40.TA.1-231-j19-1.3.H', 'mean': None}}"
     ]
    }
   ],
   "source": [
    "# Check if reversed, should be non empty:\n",
    "graph.get_edge_data('8572602','8502553')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dijkstra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dijkstra_with_time(G, first_source, arrival_time, last_target, confidence=None, \n",
    "                       confidence_step=0.01, durations_dicts=None, paths=None, departure_time = None):\n",
    "    G = G.copy()\n",
    "    #departure_time = arrival_time - MAX_TRIP_DURATION*60\n",
    "    departure_time = departure_time\n",
    "    while True:\n",
    "        \"\"\"\n",
    "        # Update durations according to confidence\n",
    "        if confidence != None:\n",
    "            if durations_dicts == None:\n",
    "                raise ValueError('You must pass durations_dicts for the confidence.')\n",
    "            # Load dict with modifications\n",
    "            if confidence not in durations_dicts:\n",
    "                edge_and_data_tuple = zip(G.edges(keys=True), \n",
    "                              map(lambda x: x[2], G.edges(data=True)))\n",
    "                edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "                durations_dicts[confidence] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                                        data['std'], \n",
    "                                                                                                        confidence)\n",
    "                                                   if data['mean'] != None and data['std'] != None\n",
    "                                                   else data['duration']\n",
    "                                                  } for e, data in edge_and_data_tuple}\n",
    "            \n",
    "            # Update graph\n",
    "            nx.set_edge_attributes(G, durations_dicts[confidence])\n",
    "        \"\"\"\n",
    "        \n",
    "        if not G.is_directed():\n",
    "            raise ValueError('Input graph is not directed while it should be.')\n",
    "\n",
    "        G_succ = G.succ \n",
    "        \n",
    "        # paths stores the nodes in dijkstra's shortest path\n",
    "        paths = {first_source: [first_source]}\n",
    "        \n",
    "        # stores the edges in dijkstra's shortest path\n",
    "        e_paths = {first_source: []}\n",
    "        \n",
    "        # dictionary of final distances to nodes\n",
    "        dist = {}  \n",
    "        \n",
    "        # dictionnary of whether it's the first time a node is visited\n",
    "        seen = {first_source: departure_time}\n",
    "\n",
    "        # use heapq with (distance,label) tuples\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "        c = count()\n",
    "        fringe = []  \n",
    "        \n",
    "        # push the source as the first node on the heap\n",
    "        push(fringe, (departure_time, next(c), first_source))\n",
    "\n",
    "        # while heap not empty\n",
    "        while fringe:\n",
    "            \n",
    "            # take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "\n",
    "            # check if node has already been looked at and has a final shortest distance: \n",
    "            if source in dist:\n",
    "                continue  # already searched this node so go to another\n",
    "\n",
    "            # take the distance to the node from the heap \n",
    "            # source starts with distance = departure_time\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the source is the last_target. \n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:\n",
    "                    \n",
    "                    # Check if walking edge: \n",
    "                    # walking edges have a departure time of -1\n",
    "                    dep_time_edge = G.get_edge_data(source, target, edge_id)['time']\n",
    "                    \n",
    "                    if dep_time_edge == -1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        # set the departure time to the distance to that node as we can leave immediatly\n",
    "                        dep_time_edge = d\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = G.get_edge_data(source, target, edge_id)['trip_id']\n",
    "                        \n",
    "                    # take only edges that have a departure time bigger \n",
    "                    # than the time it takes to get to the node\n",
    "                    if dep_time_edge < dist[source]:\n",
    "                       # move on to next edge if it's earlier \n",
    "                        continue\n",
    "                        \n",
    "                    # Check if edge is feasible (also accoring to confidence)\n",
    "                    # Check if last edge taken was not a walking edge\n",
    "                    # Check if there is at least a path of length 1 to the source node \n",
    "                    # (e.g. that this node is not the original source)\n",
    "                    if len(e_paths[source]) >= 1 and not e_paths[source][-1][2]['walk']:\n",
    "                        last_edge_source, last_edge_target, last_edge_info = e_paths[source][-1]\n",
    "                        last_delay = compute_delay_uncertainty(last_edge_info['mean'], \n",
    "                                                                   last_edge_info['std'], \n",
    "                                                                   confidence)\n",
    "                        # If we make a transport-> walk change\n",
    "                        if walking_edge:\n",
    "                            # add delay to departure time of walk as we will leave later\n",
    "                            dep_time_edge += last_delay\n",
    "                        else:\n",
    "                            # If we make a transport->transport change, check if we have time to change\n",
    "                            # To change we need that the next connection leaves >= 2 min + delay of transport\n",
    "                            # If not we cannot take that edge\n",
    "                            if current_trip_id != last_edge_info['trip_id']\\\n",
    "                            and dep_time_edge < dist[source] + 2 + last_delay:\n",
    "                                continue\n",
    "\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = G.get_edge_data(source, target, edge_id)['duration']\n",
    "                    \n",
    "                    if duration_cost is None:\n",
    "                            raise ValueError('Edge without a duration.')\n",
    "\n",
    "                    # Add the weight to the current distance to a node\n",
    "                    current_dist = dep_time_edge + duration_cost\n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:',\n",
    "                                                     'negative weights?')\n",
    "\n",
    "                    # either node has been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    elif target not in seen or current_dist < seen[target]:\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "                            edge_dict = G.get_edge_data(source, target, edge_id)\n",
    "                            \n",
    "                            edge_dict['walk'] = walking_edge\n",
    "                            edge_dict['departure_time'] = dep_time_edge\n",
    "                            \n",
    "                            e_paths[target] = e_paths[source] + [(source, target, edge_dict)]\n",
    "\n",
    "\n",
    "        # If there is no path to the last_target:\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                         'departure_time', 'walk', 'no_change', 'mean_std_null','mean','std'])\n",
    "\n",
    "        \n",
    "        # Validation: \n",
    "        if confidence == None or validate_path(e_paths[last_target], confidence, G):\n",
    "            break\n",
    "        else:\n",
    "            # else increase confidence by a confidence step and start again: \n",
    "            confidence += confidence_step\n",
    "            \n",
    "    # Path validated\n",
    "    if paths is not None:\n",
    "        nodes_data = G.nodes(data=True)\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        best_path = e_paths[last_target]\n",
    "        departure_string = minute_to_string(best_path[0][2]['departure_time'])\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                                      first_source,\n",
    "                                                                                      nodes_data[last_target]['name'],\n",
    "                                                                                      last_target, \n",
    "                                                                                      dist[last_target] - departure_time,\n",
    "                                                                                      minute_to_string(departure_time)))\n",
    "        \n",
    "        # Construct best path's data structure\n",
    "        best_path_df = pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                          'departure_time', 'walk', 'no_change', 'mean_std_null', 'mean','std'])\n",
    "        last_edge_info = False\n",
    "        for source, target, edge_info in best_path:\n",
    "            no_change = ('trip_id' in edge_info                                   # We're in a transport\n",
    "                         and last_edge_info and 'trip_id' in last_edge_info       # and last edge also\n",
    "                         and last_edge_info['trip_id'] == edge_info['trip_id'])   # and same trip_id\n",
    "            mean_std_null = 'trip_id' in edge_info and 'mean' not in edge_info or 'std' not in edge_info\n",
    "            \n",
    "            if not mean_std_null:\n",
    "                mean = edge_info['mean']\n",
    "                std = edge_info['std']\n",
    "                if  edge_info['mean'] == None or  edge_info['std'] == None: \n",
    "                    mean = edge_info['duration']\n",
    "                    std = 0\n",
    "            if 'mean' not in edge_info or 'std' not in edge_info:\n",
    "                mean = edge_info['duration']\n",
    "                std = 0\n",
    "                \n",
    "            \n",
    "            current_path_dict = {'from': nodes_data[source]['name'],\n",
    "                                 'from_id': source, \n",
    "                                 'to': nodes_data[target]['name'], \n",
    "                                 'to_id': target, \n",
    "                                 'duration': edge_info['duration'], \n",
    "                                 'total_duration': dist[target] - departure_time,\n",
    "                                 'departure_time': minute_to_string(edge_info['departure_time']), \n",
    "                                 'walk':edge_info['walk'], \n",
    "                                 'no_change': no_change, \n",
    "                                 'mean_std_null': mean_std_null,\n",
    "                                'mean':mean,\n",
    "                                'std':std}\n",
    "            best_path_df = best_path_df.append(current_path_dict, ignore_index=True)\n",
    "            last_edge_info = edge_info\n",
    "        \n",
    "        with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "            print(best_path_df)\n",
    "        return best_path_df\n",
    "    raise ValueError('Should not be here')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dijkstra_reversed(G, first_source, arrival_time, last_target, confidence=None, \n",
    "                       confidence_step=0.01, durations_dicts=None):\n",
    "    G = G.copy()\n",
    "    departure_time = -arrival_time\n",
    "\n",
    "    # inverse direction \n",
    "    temp = first_source\n",
    "    first_source = last_target\n",
    "    last_target = temp\n",
    "        \n",
    "    if not G.is_directed():\n",
    "        raise ValueError('Input graph is not directed while it should be.')\n",
    "\n",
    "    G_succ = G.succ \n",
    "        \n",
    "    # paths stores the nodes in dijkstra's shortest path\n",
    "    paths = {first_source: [first_source]}\n",
    "    # stores the edges in dijkstra's shortest path\n",
    "    e_paths = {first_source: []}\n",
    "        \n",
    "    # dictionary of final distances to nodes\n",
    "    dist = {}  \n",
    "        \n",
    "    # dictionnary of whether it's the first time a node is visited\n",
    "    seen = {first_source: departure_time}\n",
    "\n",
    "    # use heapq with (distance,label) tuples\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    c = count()\n",
    "    fringe = []  \n",
    "        \n",
    "    # push the source as the first node on the heap\n",
    "    push(fringe, (departure_time, next(c), first_source))\n",
    "    # while heap not empty\n",
    "    while True:\n",
    "        while fringe:\n",
    "            # take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "\n",
    "             # check if node has already been looked at and has a final shortest distance: \n",
    "            if source in dist:\n",
    "                  continue  # already searched this node so go to another\n",
    "\n",
    "            # take the distance to the node from the heap \n",
    "            # source starts with distance = departure_time\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the source is the last_target. \n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:  \n",
    "                    \n",
    "                    dep_time_edge = - G.get_edge_data(source, target, edge_id)['time']\n",
    "\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = G.get_edge_data(source, target, edge_id)['duration']\n",
    "                     \n",
    "                    # Check if walking edge: \n",
    "                    # walking edges have a departure time of -1\n",
    "                    if dep_time_edge == 1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        \n",
    "                        # set the departure time to the \n",
    "                        # distance to that node as we can leave immediatly\n",
    "                        dep_time_edge = d + duration_cost                  \n",
    "\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = G.get_edge_data(source, target, edge_id)['trip_id']\n",
    "\n",
    "\n",
    "                    if duration_cost is None:\n",
    "                            raise ValueError('Edge without a duration.')\n",
    "\n",
    "                    # Add the weight to the current distance to a node\n",
    "\n",
    "                    current_dist = dep_time_edge           \n",
    "                    # take only edges that have a departure time bigger \n",
    "                    # than the time it takes to get to the node\n",
    "\n",
    "                    if dep_time_edge - duration_cost < dist[source]:\n",
    "                            # move on to next edge if it's earlier \n",
    "                        continue\n",
    "\n",
    "                    # Check if edge is feasible (also accoring to confidence)\n",
    "                    # Check if last edge taken was not a walking edge\n",
    "                    # Check if there is at least a path of length 1 to the source node \n",
    "                    # (e.g. that this node is not the original source)\n",
    "                    if len(e_paths[source]) >= 1 and not walking_edge:\n",
    "                        last_edge_source, last_edge_target, last_edge_info = e_paths[source][-1]\n",
    "                        mean = G.get_edge_data(source, target, edge_id)['mean']\n",
    "                        std = G.get_edge_data(source, target, edge_id)['std']\n",
    "                        # now compute delay for current edge because in reverse\n",
    "                        last_delay = compute_delay_uncertainty(mean, std, confidence)\n",
    "\n",
    "                        # If we make a transport-> walk change\n",
    "                        if last_edge_info['walk']:\n",
    "                            # add delay to departure time of walk as we will leave later\n",
    "                            dep_time_edge -= last_delay\n",
    "                        else:\n",
    "                            # If we make a transport->transport change, check if we have time to change\n",
    "                            # To change we need that the next connection leaves >= 2 min + delay of transport\n",
    "                            # If not we cannot take that edge\n",
    "                            #if current_trip_id != last_edge_info['trip_id']\\\n",
    "                            #and dep_time_edge < dist[source] + 2 + last_delay:\n",
    "                            #   continue\n",
    "                            if current_trip_id != last_edge_info['trip_id'] and dep_time_edge - last_delay - 2 - duration_cost < dist[source]:\n",
    "                                continue                \n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:','negative weights?')\n",
    "\n",
    "                    # either node has been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    if target not in seen or current_dist < seen[target]:\n",
    "\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "\n",
    "                            edge_dict = G.get_edge_data(source, target, edge_id)\n",
    "\n",
    "                            edge_dict['walk'] = walking_edge\n",
    "                            edge_dict['departure_time'] = dep_time_edge\n",
    "                            e_paths[target] = e_paths[source] + [(source, target, edge_dict)]    \n",
    "        \n",
    "        # If there is no path to the last_target:\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', \n",
    "                                             'departure_time', 'walk', 'no_change', 'mean_std_null','mean','std'])\n",
    "\n",
    "\n",
    "        # Validation: \n",
    "        if confidence == None or validate_path_(e_paths[last_target], confidence):\n",
    "            break\n",
    "        else:\n",
    "            # else increase confidence by a confidence step and start again: \n",
    "            confidence += confidence_step\n",
    "        # Path validated\n",
    "    if paths is not None:\n",
    "        nodes_data = G.nodes(data=True)\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        \n",
    "        #reverse path:\n",
    "        best_path = []\n",
    "        for edge in e_paths[last_target][::-1]: \n",
    "            edge = (edge[1], edge[0], edge[2])\n",
    "            best_path.append(edge)           \n",
    "        num_edges = len(best_path)\n",
    "        departure_string = minute_to_string(-best_path[0][2]['departure_time'])\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}, arrival at {}'.format(nodes_data[last_target]['name'],\n",
    "                                                                                      last_target,\n",
    "                                                                                      nodes_data[first_source]['name'],\n",
    "                                                                                      first_source, \n",
    "                                                                                      arrival_time + best_path[0][2]['departure_time'],\n",
    "                                                                                      minute_to_string(-best_path[0][2]['departure_time']),\n",
    "                                                                                        minute_to_string(-best_path[num_edges-1][2]['departure_time']+\n",
    "                                                                                                        best_path[num_edges-1][2]['duration'])))\n",
    "        \n",
    "        # Construct best path's data structure\n",
    "        best_path_df = pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration',\n",
    "                                          'departure_time', 'walk', 'no_change', 'mean_std_null', 'mean','std'])\n",
    "        last_edge_info = False\n",
    "        for source, target, edge_info in best_path:\n",
    "            no_change = ('trip_id' in edge_info                                   # We're in a transport\n",
    "                         and last_edge_info and 'trip_id' in last_edge_info       # and last edge also\n",
    "                         and last_edge_info['trip_id'] == edge_info['trip_id'])   # and same trip_id\n",
    "            mean_std_null = 'trip_id' in edge_info and 'mean' not in edge_info or 'std' not in edge_info\n",
    "            \n",
    "            if not mean_std_null:\n",
    "                mean = edge_info['mean']\n",
    "                std = edge_info['std']\n",
    "                if  edge_info['mean'] == None or  edge_info['std'] == None: \n",
    "                    mean = edge_info['duration']\n",
    "                    std = 0\n",
    "            if 'mean' not in edge_info or 'std' not in edge_info:\n",
    "                mean = edge_info['duration']\n",
    "                std = 0\n",
    "                \n",
    "            current_path_dict = {'from': nodes_data[source]['name'],\n",
    "                                 'from_id': source, \n",
    "                                 'to': nodes_data[target]['name'], \n",
    "                                 'to_id': target, \n",
    "                                 'duration': edge_info['duration'], \n",
    "                                 'departure_time': minute_to_string(-edge_info['departure_time']), \n",
    "                                 'walk':edge_info['walk'], \n",
    "                                 'no_change': no_change, \n",
    "                                 'mean_std_null': mean_std_null,\n",
    "                                'mean':mean,\n",
    "                                'std':std}\n",
    "            best_path_df = best_path_df.append(current_path_dict, ignore_index=True)\n",
    "            last_edge_info = edge_info\n",
    "        \n",
    "        with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "                print(best_path_df)\n",
    "        return best_path_df\n",
    "    raise ValueError('Should not be here')\n",
    "    return e_paths[last_target], dist[last_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation:\n",
    "\n",
    "##### Feasible paths:\n",
    "Create a function that looks through a path to see if it is valid. \n",
    "So it looks for:\n",
    "- missed connections\n",
    "- transfer time of less than 2 minutes between two transports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Returns true if there is time to take all edges, and if \n",
    "when chaning from a connection to another you have at least 2 minutes. \"\"\"\n",
    "\n",
    "def is_path_valid(path):\n",
    "    last_target = path['from_id'][len(path['from_id'])-1]\n",
    "    time = convertToMinute(path['departure_time'][0]) + path['duration'][0]\n",
    "    \n",
    "    for i in range(1, len(path['from_id'])):\n",
    "        #in case an edge taken actually left before we got there (only for transport edges, not for walks)\n",
    "        if not path['walk'][i] and convertToMinute(path['departure_time'][i]) < time:\n",
    "            print('You miss this connection. Time is {} while this edge leaves at {} from {} to {}'\\\n",
    "                  .format(minute_to_string(time), path['departure_time'][i], path['from'][i], path['to'][i]))\n",
    "            return False\n",
    "        \n",
    "        #in case of change type transport -> trasnport need 2 minutes transfer:\n",
    "        if not path['no_change'][i] and not path['walk'][i]:\n",
    "            if not path['walk'][i-1]:\n",
    "                if convertToMinute(path['departure_time'][i]) < time + 2:\n",
    "                    print('You do not have time to change to this connection between {} to {} leaving at {}. You arrive at {} and need at least 2 min transfer'\\\n",
    "                          .format(path['from'][i],path['to'][i], path['departure_time'][i], minute_to_string(time)))\n",
    "                    return False\n",
    "        \n",
    "        else: \n",
    "            time = convertToMinute(path['departure_time'][i]) + path['duration'][i]\n",
    "    return True\n",
    "\n",
    "# test of is path valid:\n",
    "#assert(is_path_valid(best_path1))\n",
    "#assert(is_path_valid(best_path2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate a path:\n",
    "Then for a given path, we sample felays for transfers where we go from a transport -> walk or transport -> transport. \n",
    "\n",
    "For transport 1 -> transport 2: the delay of transport 1 will be added to its trip duration\n",
    "For transport -> walk: the delay of transport will be added to the departure time of walk \n",
    "\n",
    "After modifying these values, we check whether the path is still feasible. We repeat this operation a ceertain number of times and report the percentage of feasible paths. \n",
    "\n",
    "For the moment, delays are sampled from an absolute normal distribution (**?good?**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_path_(path, confidence):\n",
    "    num_tries = 10\n",
    "    num_valids = 0\n",
    "    \n",
    "    for i in range(num_tries):\n",
    "        path_copy = path.copy()\n",
    "        for i in range(len(path['from_id'])):\n",
    "            #only for transfers etiher to other trains or to walking: \n",
    "            if i > 1 and not path['no_change'][i]:\n",
    "                mean = path['mean'][i-1]\n",
    "                std = path['std'][i-1]\n",
    "                #sample a delay:\n",
    "                #delay = compute_delay_uncertainty(mean, std, confidence)\n",
    "                \n",
    "                # calcluate delay for connection of before:\n",
    "                if std != 0:\n",
    "                    delay = np.random.normal(mean, std)\n",
    "                    if delay <0:\n",
    "                        delay = 0\n",
    "                else: delay = 0\n",
    "                \n",
    "                # if its between two transports we just add it to trip duration:\n",
    "                if not path['walk'][i] and not path['walk'][i-1]:\n",
    "                    print('Delay of {} for {} to {}'.format(delay, path_copy['from'][i-1], path_copy['to'][i-1]))\n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                \n",
    "                # transfer from trans to walk:\n",
    "                if not path['walk'][i-1] and path['walk'][i]:\n",
    "                    # if a train to a walk is delayed, the walk needs to leave later:\n",
    "                    #need to leave at the time it takes for the delayed connection to arrive, \n",
    "                    # so if delayed need to start walking later: \n",
    "                    \n",
    "                    if delay !=0:\n",
    "                        print('Delay of {} for {} to {}, need to start walking later from {}'\\\n",
    "                                  .format(delay, path_copy['from'][i-1], path_copy['to'][i-1], path_copy['to'][i-1]))\n",
    "                    \n",
    "                    #add duration to transp: \n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                    \n",
    "                    #delay the start of walk:\n",
    "                    arrival_of_edge_before = path_copy['duration'][i-1]+convertToMinute(path_copy['departure_time'][i-1])\n",
    "                    \n",
    "                    # need to start later:\n",
    "                    new_dep_time = minute_to_string(arrival_of_edge_before)\n",
    "                    path_copy['departure_time'][i] = new_dep_time\n",
    "        \n",
    "        if is_path_valid(path_copy):\n",
    "            num_valids += 1\n",
    "        perc = num_valids/float(num_tries)\n",
    "    return perc >= confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create duration dictionnaries if needed\n",
    "\n",
    "Code commented, don't have the permission to **change** a file, can write if put another path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durations_dicts = {}\n",
    "edge_and_data_tuple = zip(graph.edges(keys=True),\n",
    "              map(lambda x: x[2], graph.edges(data=True)))\n",
    "edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "for c in [0.25, 0.5, 0.75, 0.9, 0.95, 0.98, 0.99]:\n",
    "    durations_dicts[c] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                            data['std'], \n",
    "                                                                                            c)\n",
    "                                       if data['mean'] != None and data['std'] != None\n",
    "                                       else data['duration']\n",
    "                                      } for e, data in edge_and_data_tuple}\n",
    "    \n",
    "\"\"\" Conversion to json \"\"\"\n",
    "durations_dicts_for_json = {}\n",
    "for c in durations_dicts.keys():\n",
    "    durations_dicts_for_json[c] = {str(k): v for k, v in durations_dicts[c].items()}\n",
    "\n",
    "print('Length of json:', len(json.dumps(durations_dicts_for_json))) -> 30106955\n",
    "\n",
    "\"\"\" Save to hdfs \"\"\"\n",
    "sc.parallelize([json.dumps(durations_dicts_for_json)]).coalesce(1).saveAsTextFile('/user/{}/durations_for_confidence_.json'.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Dijkstra reversed algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049) in 25.14 minutes, departure at 12:04, arrival at 12:29\n",
      "             from         from_id              to           to_id  duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0       Zurich HB         8503000       Zurich HB  8503000:0:4...  2.135259          12:04   True     False          True  2.135259        0\n",
      "1       Zurich HB  8503000:0:4...  Zurich Hard...     8503020:0:3  2.000000          12:07  False     False         False  0.336499  1.09469\n",
      "2  Zurich Hard...     8503020:0:3  Zurich Oerl...     8503006:0:8  5.000000          12:09  False      True         False  5.000000        0\n",
      "3  Zurich Oerl...     8503006:0:8      Glattbrugg     8503310:0:3  2.000000          12:15  False      True         False  2.000000        0\n",
      "4      Glattbrugg     8503310:0:3  Glattbrugg,...         8590620  3.063448          12:19   True     False          True  3.063448        0\n",
      "5  Glattbrugg,...         8590620  Glattbrugg,...         8590626  1.000000          12:23  False     False         False  0.639793  1.40383\n",
      "6  Glattbrugg,...         8590626  Glattpark, ...         8591830  2.000000          12:24  False      True         False  0.829374  1.32294\n",
      "7  Glattpark, ...         8591830  Zurich, Fer...         8591128  1.000000          12:26  False      True         False  0.891561   1.4187\n",
      "8  Zurich, Fer...         8591128  Zurich, Auzelg         8591049  2.000000          12:27  False      True         False  0.956600  1.35904"
     ]
    }
   ],
   "source": [
    "# Test Tao 1: \n",
    "\"\"\"\n",
    "Route 1: HB -> Auszelg\n",
    "20.TA.26-9-A-j19-1.2.H: 8503000:0:41/42 at 12:07:00 ~ 8503310:0:3 at 12:17:00\n",
    "Walking: 8503310:0:3 ~ 8590620\n",
    "168.TA.26-12-A-j19-1.2.H: 8590620 at 12:23:00 ~ 8591049 at 12:29:00\n",
    "\"\"\"\n",
    "best_path1 = dijkstra_reversed(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057) in 22.00 minutes, departure at 12:08, arrival at 12:30\n",
      "             from  from_id              to    to_id  duration departure_time   walk no_change mean_std_null      mean       std\n",
      "0  Zurich, Tri...  8503610  Zurich, In ...  8591214  2.000000          12:08  False     False         False  1.470458  2.517784\n",
      "1  Zurich, In ...  8591214  Zurich, Gol...  8591163  1.000000          12:10  False      True         False  1.338457  1.940935\n",
      "2  Zurich, Gol...  8591163  Zurich, Alb...  8591036  1.000000          12:11  False      True         False  1.284314  2.041064\n",
      "3  Zurich, Alb...  8591036  Zurich, Alb...  8591037  1.000000          12:12  False      True         False  1.276941  2.026404\n",
      "4  Zurich, Alb...  8591037  Zurich, Unt...  8591408  1.000000          12:13  False      True         False  1.053628  1.640792\n",
      "5  Zurich, Unt...  8591408  Zurich, Rau...  8591311  2.000000          12:14  False      True         False  1.184472  1.532399\n",
      "6  Zurich, Rau...  8591311  Zurich, Lin...  8591258  2.000000          12:16  False      True         False  1.080137  1.420565\n",
      "7  Zurich, Lin...  8591258  Zurich, Bri...  8591097  0.000000          12:18  False      True         False  0.983224  1.457860\n",
      "8  Zurich, Bri...  8591097  Zurich Alts...  8591057  8.167871          12:21   True     False          True  8.167871  0.000000"
     ]
    }
   ],
   "source": [
    "# Test 2: \n",
    "\"\"\"\n",
    "Route 2:\n",
    "Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057)\n",
    "\"\"\"\n",
    "#From HB zu Auszelg:\n",
    "best_path1 = dijkstra_reversed(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm improv pour arrival time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrements = [10, 5, 2, 1, 0]\n",
    "source = '8503000'\n",
    "target = '8591122'\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "\n",
    "arrival_time = arrival_hour*60+arrival_minute\n",
    "\n",
    "def depart_time(arrival_time, source, target, decrements):\n",
    "    #start with two hours before:\n",
    "    dep = arrival_time - MAX_TRIP_DURATION*60\n",
    "    path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = dep)\n",
    "    num_edges = len(path['total_duration'])\n",
    "    duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "    first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "    arrival_diff = arrival_time - first_arrival\n",
    "    \n",
    "    departures = [dep]\n",
    "    \n",
    "    if arrival_diff < 0:\n",
    "        raise ErrorValue('Arrives after wanted arrival time')\n",
    "    for i in decrements:\n",
    "        dep = arrival_time - duration - i\n",
    "        path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = dep)\n",
    "        num_edges = len(path['total_duration'])\n",
    "        duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "        first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "        arrival_diff = arrival_time - first_arrival\n",
    "        \n",
    "        if arrival_diff < 0:\n",
    "            return departures[0]\n",
    "        \n",
    "        departures.insert(0, dep)\n",
    "\n",
    "        print('Start with {} minutes difference'.format(arrival_diff))\n",
    "        print('Trip takes {} minutes'.format(duration))\n",
    "\n",
    "        \n",
    "    return departures[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
