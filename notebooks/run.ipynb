{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'dslab-group_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6532</td><td>application_1589299642358_1021</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1021/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1021_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6545</td><td>application_1589299642358_1034</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1034/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1034_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6555</td><td>application_1589299642358_1044</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1044/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1044_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6560</td><td>application_1589299642358_1049</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1049/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1049_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6561</td><td>application_1589299642358_1050</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1050/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1050_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6562</td><td>application_1589299642358_1051</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1051/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1051_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6563</td><td>application_1589299642358_1052</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1052/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1052_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6564</td><td>application_1589299642358_1053</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1053/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1053_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6567</td><td>application_1589299642358_1056</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1056/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1056_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6568</td><td>application_1589299642358_1057</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1057/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1057_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6577</td><td>application_1589299642358_1066</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1066/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1066_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6578</td><td>application_1589299642358_1067</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1067/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1067_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6579</td><td>application_1589299642358_1068</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1068/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1068_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6580</td><td>application_1589299642358_1069</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1069/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1069_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6581</td><td>application_1589299642358_1070</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1070/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1070_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6582</td><td>application_1589299642358_1071</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1071/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1071_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6583</td><td>application_1589299642358_1072</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1072/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1072_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6587</td><td>application_1589299642358_1076</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1076/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1076_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6591</td><td>application_1589299642358_1080</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1080/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1080_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')\n",
    "\n",
    "def minute_to_string(m):\n",
    "    hour, minute = m // 60, m - 60*(m//60)\n",
    "    time_string = '{:02}:{:02}'.format(int(hour), int(minute))\n",
    "    \n",
    "    return time_string\n",
    "\n",
    "def string_to_minute(s):\n",
    "    h, m, _ = s.split(':')\n",
    "    h,m = int(h), int(m)\n",
    "    \n",
    "    return h*60+m\n",
    "\n",
    "def get_time(graph, source, target, j):\n",
    "    attr = graph.edges[(source, target, j)]\n",
    "    return attr['time']\n",
    "\n",
    "def get_weight(graph, source, target, j):\n",
    "    attr = graph.edges[(source, target, j)]\n",
    "    return attr['duration']\n",
    "\n",
    "def normal_dijkstra(G, first_source, paths=None, cutoff=None, last_target=None):\n",
    "    \n",
    "    G_succ = G.succ if G.is_directed() else G.adj\n",
    "    paths = {first_source: [first_source]}\n",
    "\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    dist = {}  # dictionary of final distances\n",
    "    \n",
    "    # dictionnary of wthether it's the first time a node is visited\n",
    "    seen = {first_source: 0}\n",
    "\n",
    "    c = count()\n",
    "    fringe = []  # use heapq with (distance,label) tuples\n",
    "    push(fringe, (0, next(c), first_source))\n",
    "    \n",
    "    while fringe:\n",
    "        #take the node to look at: \n",
    "        (d, _, source) = pop(fringe)\n",
    "        \n",
    "        # check if node has already been looked at: \n",
    "        if source in dist:\n",
    "            continue  # already searched this node.\n",
    "        \n",
    "        # update the distance of the node\n",
    "        dist[source] = d\n",
    "        \n",
    "        #stop if the node we look at is the target obviously\n",
    "        if source == last_target:\n",
    "            break\n",
    "            \n",
    "        # Look at all direct descendents from the source node: \n",
    "        for target, edges in G_succ[source].items():\n",
    "            # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "            for edge_id in edges:\n",
    "                \n",
    "                # Get the duration between two nodes:\n",
    "                cost = get_weight_custom(G, source, target, edge_id)\n",
    "                \n",
    "                if cost is None:\n",
    "                        continue\n",
    "                \n",
    "                # Add the weight to the current distance of a node\n",
    "                current_dist = dist[source] + get_weight_custom(G, source, target, edge_id)\n",
    "                \n",
    "                # if target has already been visited once and has a final distance:\n",
    "                if target in dist:\n",
    "                        # if we find a distance smaller than the actual distance in dic\n",
    "                        # raise error because dic distances contains only final distances\n",
    "                        if current_dist < dist[target]:\n",
    "                            raise ValueError('Contradictory paths found:',\n",
    "                                             'negative weights?')\n",
    "                # either node node been seen before or the current distance is smaller than the \n",
    "                # proposed distance in seen[target]:\n",
    "                elif target not in seen or current_dist < seen[target]:\n",
    "                    # update the seen distance\n",
    "                    seen[target] = current_dist\n",
    "                    # push it onto the heap so that we will look at its descendants later\n",
    "                    push(fringe, (current_dist, next(c), target))\n",
    "                    \n",
    "                    # update the paths till target:\n",
    "                    if paths is not None:\n",
    "                        paths[target] = paths[source] + [target]\n",
    "    if paths is not None:\n",
    "        return (dist, paths)\n",
    "    return dist\n",
    "\n",
    "def dijkstra_with_time(G, first_source, INPUT_TIME, paths=None, last_target=None):\n",
    "    \n",
    "    G_succ = G.succ if G.is_directed() else G.adj\n",
    "    \n",
    "    paths = {first_source: [first_source]}\n",
    "    e_paths = {first_source: []}\n",
    "\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    dist = {}  # dictionary of final distances\n",
    "    \n",
    "    # dictionnary of wthether it's the first time a node is visited\n",
    "    seen = {first_source: INPUT_TIME}\n",
    "    \n",
    "    \n",
    "    c = count()\n",
    "    fringe = []  # use heapq with (distance,label) tuples\n",
    "    \n",
    "    #push(fringe, (0, next(c), first_source))\n",
    "    push(fringe, (INPUT_TIME, next(c), first_source))\n",
    "    \n",
    "    while fringe:\n",
    "        #take the node to look at: \n",
    "        (d, _, source) = pop(fringe)\n",
    "        #print('Looking at node: '+source)\n",
    "        \n",
    "        # check if node has already been looked at: \n",
    "        if source in dist:\n",
    "            continue  # already searched this node.\n",
    "        \n",
    "        # update the distance of the node\n",
    "        dist[source] = d\n",
    "        \n",
    "        #stop if the node we look at is the target obviously\n",
    "        if source == last_target:\n",
    "            break\n",
    "        \n",
    "        # Look at all direct descendents from the source node: \n",
    "        for target, edges in G_succ[source].items():\n",
    "            # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "            for edge_id in edges:\n",
    "                dep_time_edge = get_time(G, source, target, edge_id)\n",
    "                if dep_time_edge == -1:\n",
    "                    dep_time_edge = d\n",
    "                \n",
    "                # Note: checker si chgt de ligne faire +2min\n",
    "                if dep_time_edge >= dist[source]:\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = get_weight(G, source, target, edge_id)\n",
    "\n",
    "                    if duration_cost is None:\n",
    "                            continue\n",
    "\n",
    "                    # Add the weight to the current distance of a node\n",
    "                    current_dist = dep_time_edge + duration_cost\n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:',\n",
    "                                                 'negative weights?')\n",
    "\n",
    "                    # either node node been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    elif target not in seen or current_dist < seen[target]:\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "                            #paths[target] = paths[source] + [target]\n",
    "                            e_paths[target] = e_paths[source] + [(source, target, {'departure_time':dep_time_edge, 'duration':duration_cost})]\n",
    "                            \n",
    "    if  last_target not in e_paths:\n",
    "        print('Error: No paths to the source')\n",
    "        return (0, [])\n",
    "        #raise ValueError('No paths exist to the source') \n",
    "    \n",
    "    if paths is not None:\n",
    "        #return (dist, paths, e_paths)\n",
    "        #return (dist, e_paths)<\n",
    "        \n",
    "        #for _ in range(100):\n",
    "            #Validate path\n",
    "            #for e in path:\n",
    "                #sample_gaussian\n",
    "                #check if miss connection\n",
    "            #If > 0 connection missed, path missed\n",
    "        # if 95% must have missed < 5 path\n",
    "        # if path not validated -> starts with smaller threshold \n",
    "        \n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        best_path = e_paths[last_target]\n",
    "        departure_string = minute_to_string(best_path[0][2]['departure_time'])\n",
    "        stations_id = map(lambda x: x[0], best_path)\n",
    "        \n",
    "        nodes_data = graph.nodes(data=True)\n",
    "        print('Going from {} ({}) to {} ({}), arrival at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                   first_source,\n",
    "                                                                   nodes_data[last_target]['name'],\n",
    "                                                                   last_target, 'planned_arrival'))\n",
    "        for s, t, info in best_path:\n",
    "            print('\\t{} ({}) -> {} ({}), {:.2f}\\' departure at {}'.format(nodes_data[s]['name'], s,\n",
    "                                                                          nodes_data[t]['name'], t,\n",
    "                                                                          info['duration'],\n",
    "                                                                          minute_to_string(info['departure_time'])))\n",
    "        \n",
    "        return (dist[last_target], e_paths[last_target])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format: day_id, \"hour:minute:00\"\n",
    "day_id, hour, minute = 4, 12, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "\n",
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()\n",
    "\n",
    "# TODO filtrer les nodes pour que ce soit reachable\n",
    "\n",
    "graph.add_nodes_from(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Temp for problem of encoding\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = nodes_data[n]['name'].replace(u'\\xfc', 'u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import pandas as pd\n",
    "walking_times = pd.read_pickle('pickle_walking_times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'walking_times' as 'walking_times' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['duration']+2}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "def create_edges_for_trip(edges_df, day_id, hour, minute):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    arrival_minute = hour*60+minute\n",
    "    min_dep_time = arrival_minute - 60*60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_minute))\n",
    "\n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time'])})).collect()\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, hour, minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = graph.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049), arrival at planned_arrival\n",
      "\tZurich HB (8503000) -> Zurich, Stampfenbachplatz (8591379), 7.59' departure at 12:05\n",
      "\tZurich, Stampfenbachplatz (8591379) -> Zurich, Beckenhof (8591071), 11.84' departure at 12:12\n",
      "\tZurich, Beckenhof (8591071) -> Zurich, Kronenstrasse (8591237), 10.84' departure at 12:24\n",
      "\tZurich, Kronenstrasse (8591237) -> Zurich, Schaffhauserplatz (8591335), 10.19' departure at 12:35\n",
      "\tZurich, Schaffhauserplatz (8591335) -> Zurich, Laubiweg (8591246), 10.28' departure at 12:45\n",
      "\tZurich, Laubiweg (8591246) -> Zurich, Bucheggplatz (8591101), 10.90' departure at 12:55\n",
      "\tZurich, Bucheggplatz (8591101) -> Zurich, Radiostudio (8591307), 10.44' departure at 13:06\n",
      "\tZurich, Radiostudio (8591307) -> Zurich, Bad Allenmoos (8591053), 11.55' departure at 13:17\n",
      "\tZurich, Bad Allenmoos (8591053) -> Zurich, Regensbergbrucke (8591314), 8.89' departure at 13:28\n",
      "\tZurich, Regensbergbrucke (8591314) -> Zurich Oerlikon (8503006:0:6), 11.99' departure at 13:37\n",
      "\tZurich Oerlikon (8503006:0:6) -> Zurich Oerlikon, Bahnhof Ost (8591063), 6.14' departure at 13:49\n",
      "\tZurich Oerlikon, Bahnhof Ost (8591063) -> Zurich, Leutschenbach (8591256), 10.74' departure at 13:55\n",
      "\tZurich, Leutschenbach (8591256) -> Zurich, Hagenholz (8591172), 8.39' departure at 14:06\n",
      "\tZurich, Hagenholz (8591172) -> Zurich, Riedbach (8591318), 6.02' departure at 14:14\n",
      "\tZurich, Riedbach (8591318) -> Zurich, Genossenschaftsstrasse (8591225), 8.52' departure at 14:20\n",
      "\tZurich, Genossenschaftsstrasse (8591225) -> Zurich, Auzelg (8591049), 11.27' departure at 14:29"
     ]
    }
   ],
   "source": [
    "time, path = dijkstra_with_time(G=graph, first_source='8503000', last_target='8591049', INPUT_TIME=hour*60+minute)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
