{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run:\n",
    "Only notebook to run ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A session has already been started. If you intend to recreate the session with new configurations, please include the -f argument.\n"
     ]
    }
   ],
   "source": [
    "%%configure\n",
    "{\"pyFiles\": [\"/user/gottraux/dijkstra_algorithms.py\"],\n",
    " \"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\"\"\"\n",
    "To load (or reload) into hdfs:\n",
    "hdfs dfs -rm /user/${JUPYTERHUB_USER}/dijkstra_algorithms.py 2>/dev/null\n",
    "hdfs dfs -copyFromLocal notebooks/dijkstra_algorithms.py /user/${JUPYTERHUB_USER}/\n",
    "\"\"\"\n",
    "from dijkstra_algorithms import *\n",
    "\n",
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import pandas as pd\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "#username = 'gottraux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges_with_mean_and_std_sec.orc\".format(username))\n",
    "\n",
    "#durations_dicts = json.loads(sc.textFile('/user/{}/durations_for_confidence_.json'.format(username)).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_times = pd.read_pickle('walking_edges.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'walking_times' as 'walking_times' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reverse edges\n",
    "#edges_walking = (walking_times.withColumnRenamed('source', 'temp')\n",
    "#                 .withColumnRenamed('target', 'source')\n",
    "#                 .withColumnRenamed('temp', 'target').toPandas())\n",
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['walk_duration']}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove dics from dijkstra time for the moment and make it return the mean and std as well because we need it to validate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dijkstra_with_time(G, first_source, arrival_time, last_target, confidence=None, \n",
    "                       confidence_step=0.01, durations_dicts=None, paths=None):\n",
    "    G = G.copy()\n",
    "    departure_time = arrival_time - MAX_TRIP_DURATION*60\n",
    "    \n",
    "    while True:\n",
    "        \"\"\"\n",
    "        # Update durations according to confidence\n",
    "        if confidence != None:\n",
    "            if durations_dicts == None:\n",
    "                raise ValueError('You must pass durations_dicts for the confidence.')\n",
    "            # Load dict with modifications\n",
    "            if confidence not in durations_dicts:\n",
    "                edge_and_data_tuple = zip(G.edges(keys=True), \n",
    "                              map(lambda x: x[2], G.edges(data=True)))\n",
    "                edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "                durations_dicts[confidence] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                                        data['std'], \n",
    "                                                                                                        confidence)\n",
    "                                                   if data['mean'] != None and data['std'] != None\n",
    "                                                   else data['duration']\n",
    "                                                  } for e, data in edge_and_data_tuple}\n",
    "            \n",
    "            # Update graph\n",
    "            nx.set_edge_attributes(G, durations_dicts[confidence])\n",
    "        \"\"\"\n",
    "        \n",
    "        if not G.is_directed():\n",
    "            raise ValueError('Input graph is not directed while it should be.')\n",
    "\n",
    "        G_succ = G.succ \n",
    "        \n",
    "        # paths stores the nodes in dijkstra's shortest path\n",
    "        paths = {first_source: [first_source]}\n",
    "        \n",
    "        # stores the edges in dijkstra's shortest path\n",
    "        e_paths = {first_source: []}\n",
    "        \n",
    "        # dictionary of final distances to nodes\n",
    "        dist = {}  \n",
    "        \n",
    "        # dictionnary of whether it's the first time a node is visited\n",
    "        seen = {first_source: departure_time}\n",
    "\n",
    "        # use heapq with (distance,label) tuples\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "        c = count()\n",
    "        fringe = []  \n",
    "        \n",
    "        # push the source as the first node on the heap\n",
    "        push(fringe, (departure_time, next(c), first_source))\n",
    "\n",
    "        # while heap not empty\n",
    "        while fringe:\n",
    "            \n",
    "            # take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "\n",
    "            # check if node has already been looked at and has a final shortest distance: \n",
    "            if source in dist:\n",
    "                continue  # already searched this node so go to another\n",
    "\n",
    "            # take the distance to the node from the heap \n",
    "            # source starts with distance = departure_time\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the source is the last_target. \n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:\n",
    "                    \n",
    "                    # Check if walking edge: \n",
    "                    # walking edges have a departure time of -1\n",
    "                    dep_time_edge = G.get_edge_data(source, target, edge_id)['time']\n",
    "                    \n",
    "                    if dep_time_edge == -1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        # set the departure time to the distance to that node as we can leave immediatly\n",
    "                        dep_time_edge = d\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = G.get_edge_data(source, target, edge_id)['trip_id']\n",
    "                        \n",
    "                    # take only edges that have a departure time bigger \n",
    "                    # than the time it takes to get to the node\n",
    "                    if dep_time_edge < dist[source]:\n",
    "                       # move on to next edge if it's earlier \n",
    "                        continue\n",
    "                        \n",
    "                    # Check if edge is feasible (also accoring to confidence)\n",
    "                    # Check if last edge taken was not a walking edge\n",
    "                    # Check if there is at least a path of length 1 to the source node \n",
    "                    # (e.g. that this node is not the original source)\n",
    "                    if len(e_paths[source]) >= 1 and not e_paths[source][-1][2]['walk']:\n",
    "                        last_edge_source, last_edge_target, last_edge_info = e_paths[source][-1]\n",
    "                        last_delay = compute_delay_uncertainty(last_edge_info['mean'], \n",
    "                                                                   last_edge_info['std'], \n",
    "                                                                   confidence)\n",
    "                        # If we make a transport-> walk change\n",
    "                        if walking_edge:\n",
    "                            # add delay to departure time of walk as we will leave later\n",
    "                            dep_time_edge += last_delay\n",
    "                        else:\n",
    "                            # If we make a transport->transport change, check if we have time to change\n",
    "                            # To change we need that the next connection leaves >= 2 min + delay of transport\n",
    "                            # If not we cannot take that edge\n",
    "                            if current_trip_id != last_edge_info['trip_id']\\\n",
    "                            and dep_time_edge < dist[source] + 2 + last_delay:\n",
    "                                continue\n",
    "\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = G.get_edge_data(source, target, edge_id)['duration']\n",
    "                    \n",
    "                    if duration_cost is None:\n",
    "                            raise ValueError('Edge without a duration.')\n",
    "\n",
    "                    # Add the weight to the current distance to a node\n",
    "                    current_dist = dep_time_edge + duration_cost\n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:',\n",
    "                                                     'negative weights?')\n",
    "\n",
    "                    # either node has been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    elif target not in seen or current_dist < seen[target]:\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "                            edge_dict = G.get_edge_data(source, target, edge_id)\n",
    "                            \n",
    "                            edge_dict['walk'] = walking_edge\n",
    "                            edge_dict['departure_time'] = dep_time_edge\n",
    "                            \n",
    "                            e_paths[target] = e_paths[source] + [(source, target, edge_dict)]\n",
    "\n",
    "\n",
    "        # If there is no path to the last_target:\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                         'departure_time', 'walk', 'no_change', 'mean_std_null','mean','std'])\n",
    "\n",
    "        \n",
    "        # Validation: \n",
    "        if confidence == None or validate_path(e_paths[last_target], confidence, G):\n",
    "            break\n",
    "        else:\n",
    "            # else increase confidence by a confidence step and start again: \n",
    "            confidence += confidence_step\n",
    "            \n",
    "    # Path validated\n",
    "    if paths is not None:\n",
    "        nodes_data = G.nodes(data=True)\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        best_path = e_paths[last_target]\n",
    "        departure_string = minute_to_string(best_path[0][2]['departure_time'])\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                                      first_source,\n",
    "                                                                                      nodes_data[last_target]['name'],\n",
    "                                                                                      last_target, \n",
    "                                                                                      dist[last_target] - departure_time,\n",
    "                                                                                      minute_to_string(departure_time)))\n",
    "        \n",
    "        # Construct best path's data structure\n",
    "        best_path_df = pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                          'departure_time', 'walk', 'no_change', 'mean_std_null', 'mean','std'])\n",
    "        last_edge_info = False\n",
    "        for source, target, edge_info in best_path:\n",
    "            no_change = ('trip_id' in edge_info                                   # We're in a transport\n",
    "                         and last_edge_info and 'trip_id' in last_edge_info       # and last edge also\n",
    "                         and last_edge_info['trip_id'] == edge_info['trip_id'])   # and same trip_id\n",
    "            mean_std_null = 'trip_id' in edge_info and 'mean' not in edge_info or 'std' not in edge_info\n",
    "            \n",
    "            if not mean_std_null:\n",
    "                mean = edge_info['mean']\n",
    "                std = edge_info['std']\n",
    "                if  edge_info['mean'] == None or  edge_info['std'] == None: \n",
    "                    mean = edge_info['duration']\n",
    "                    std = 0\n",
    "            if 'mean' not in edge_info or 'std' not in edge_info:\n",
    "                mean = edge_info['duration']\n",
    "                std = 0\n",
    "                \n",
    "            \n",
    "            current_path_dict = {'from': nodes_data[source]['name'],\n",
    "                                 'from_id': source, \n",
    "                                 'to': nodes_data[target]['name'], \n",
    "                                 'to_id': target, \n",
    "                                 'duration': edge_info['duration'], \n",
    "                                 'total_duration': dist[target] - departure_time,\n",
    "                                 'departure_time': minute_to_string(edge_info['departure_time']), \n",
    "                                 'walk':edge_info['walk'], \n",
    "                                 'no_change': no_change, \n",
    "                                 'mean_std_null': mean_std_null,\n",
    "                                'mean':mean,\n",
    "                                'std':std}\n",
    "            best_path_df = best_path_df.append(current_path_dict, ignore_index=True)\n",
    "            last_edge_info = edge_info\n",
    "        \n",
    "        with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "            print(best_path_df)\n",
    "        return best_path_df\n",
    "    raise ValueError('Should not be here')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation:\n",
    "\n",
    "##### Feasible paths:\n",
    "Create a function that looks through a path to see if it is valid. \n",
    "So it looks for:\n",
    "- missed connections\n",
    "- transfer time of less than 2 minutes between two transports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Returns true if there is time to take all edges, and if \n",
    "when chaning from a connection to another you have at least 2 minutes. \"\"\"\n",
    "\n",
    "def is_path_valid(path):\n",
    "    last_target = path['from_id'][len(path['from_id'])-1]\n",
    "    time = convertToMinute(path['departure_time'][0]) + path['duration'][0]\n",
    "    \n",
    "    for i in range(1, len(path['from_id'])):\n",
    "        #in case an edge taken actually left before we got there (only for transport edges, not for walks)\n",
    "        if not path['walk'][i] and convertToMinute(path['departure_time'][i]) < time:\n",
    "            print('You miss this connection. Time is {} while this edge leaves at {} from {} to {}'\\\n",
    "                  .format(minute_to_string(time), path['departure_time'][i], path['from'][i], path['to'][i]))\n",
    "            return False\n",
    "        \n",
    "        #in case of change type transport -> trasnport need 2 minutes transfer:\n",
    "        if not path['no_change'][i] and not path['walk'][i]:\n",
    "            if not path['walk'][i-1]:\n",
    "                if convertToMinute(path['departure_time'][i]) < time + 2:\n",
    "                    print('You do not have time to change to this connection between {} to {} leaving at {}. You arrive at {} and need at least 2 min transfer'\\\n",
    "                          .format(path['from'][i],path['to'][i], path['departure_time'][i], minute_to_string(time)))\n",
    "                    return False\n",
    "        \n",
    "        else: \n",
    "            time = convertToMinute(path['departure_time'][i]) + path['duration'][i]\n",
    "    return True\n",
    "\n",
    "# test of is path valid:\n",
    "#assert(is_path_valid(best_path1))\n",
    "#assert(is_path_valid(best_path2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate a path:\n",
    "Then for a given path, we sample felays for transfers where we go from a transport -> walk or transport -> transport. \n",
    "\n",
    "For transport 1 -> transport 2: the delay of transport 1 will be added to its trip duration\n",
    "For transport -> walk: the delay of transport will be added to the departure time of walk \n",
    "\n",
    "After modifying these values, we check whether the path is still feasible. We repeat this operation a ceertain number of times and report the percentage of feasible paths. \n",
    "\n",
    "For the moment, delays are sampled from an absolute normal distribution (**?good?**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_path_(path, confidence):\n",
    "    num_tries = 10\n",
    "    num_valids = 0\n",
    "    \n",
    "    for i in range(num_tries):\n",
    "        path_copy = path.copy()\n",
    "        for i in range(len(path['from_id'])):\n",
    "            #only for transfers etiher to other trains or to walking: \n",
    "            if i > 1 and not path['no_change'][i]:\n",
    "                mean = path['mean'][i-1]\n",
    "                std = path['std'][i-1]\n",
    "                #sample a delay:\n",
    "                #delay = compute_delay_uncertainty(mean, std, confidence)\n",
    "                \n",
    "                # calcluate delay for connection of before:\n",
    "                if std != 0:\n",
    "                    \n",
    "                    #delay = np.absolute(np.random.normal(mean, std))\n",
    "                    delay = np.random.normal(mean, std)\n",
    "                else: delay = 0\n",
    "                \n",
    "                # if its between two transports we just add it to trip duration:\n",
    "                if not path['walk'][i] and not path['walk'][i-1]:\n",
    "                    print('Delay of {} for {} to {}'.format(delay, path_copy['from'][i-1], path_copy['to'][i-1]))\n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                \n",
    "                # transfer from trans to walk:\n",
    "                if not path['walk'][i-1] and path['walk'][i]:\n",
    "                    # if a train to a walk is delayed, the walk needs to leave later:\n",
    "                    #need to leave at the time it takes for the delayed connection to arrive, \n",
    "                    # so if delayed need to start walking later: \n",
    "                    \n",
    "                    if delay !=0:\n",
    "                        print('Delay of {} for {} to {}, need to start walking later from {}'\\\n",
    "                                  .format(delay, path_copy['from'][i-1], path_copy['to'][i-1], path_copy['to'][i-1]))\n",
    "                    \n",
    "                    #add duration to transp: \n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                    \n",
    "                    #delay the start of walk:\n",
    "                    arrival_of_edge_before = path_copy['duration'][i-1]+convertToMinute(path_copy['departure_time'][i-1])\n",
    "                    \n",
    "                    # need to start later:\n",
    "                    new_dep_time = minute_to_string(arrival_of_edge_before)\n",
    "                    path_copy['departure_time'][i] = new_dep_time\n",
    "        \n",
    "        if is_path_valid(path_copy):\n",
    "            num_valids += 1\n",
    "    return num_valids/float(num_tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 32.00 minutes, departure at 10:30\n",
      "              from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean       std\n",
      "0        Zurich HB  8503000  Zurich, Bah...  8587349  4.704125        4.704125          10:30   True     False          True  4.704125         0\n",
      "1   Zurich, Bah...  8587349  Zurich, Sta...  8591379  1.000000        7.000000          10:36  False     False         False  1.918103    1.3509\n",
      "2   Zurich, Sta...  8591379  Zurich, Nor...  8591291  3.000000       10.000000          10:37  False      True         False  1.183184   1.15276\n",
      "3   Zurich, Nor...  8591291  Zurich, Let...  8591251  1.000000       11.000000          10:40  False      True         False  1.297521   1.28782\n",
      "4   Zurich, Let...  8591251  Zurich Wipk...  8591066  1.000000       12.000000          10:41  False      True         False  1.255934   1.03589\n",
      "5   Zurich Wipk...  8591066  Zurich, Ros...  8591323  2.000000       14.000000          10:42  False      True         False  1.490386   1.74922\n",
      "6   Zurich, Ros...  8591323  Zurich, Leh...  8591247  1.000000       15.000000          10:44  False      True         False  1.389154   1.77222\n",
      "7   Zurich, Leh...  8591247  Zurich, Reb...  8591312  1.000000       16.000000          10:45  False      True         False  1.231264   1.10861\n",
      "8   Zurich, Reb...  8591312  Zurich, Kem...  8591226  1.000000       17.000000          10:46  False      True         False  1.246333   1.11333\n",
      "9   Zurich, Kem...  8591226  Zurich, Sch...  8591353  1.000000       18.000000          10:47  False      True         False  1.229301   1.09003\n",
      "10  Zurich, Sch...  8591353  Zurich, Mei...  8576240  1.000000       19.000000          10:48  False      True         False  1.066935  0.976204\n",
      "11  Zurich, Mei...  8576240  Zurich, Hon...  8591201  1.000000       30.000000          10:59  False     False         False  1.157511   1.10584\n",
      "12  Zurich, Hon...  8591201  Zurich, ETH...  8591122  2.000000       32.000000          11:00  False      True         False  1.026429   1.54772\n",
      "Delay of 3.50008409071 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "Delay of 11.9683786995 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "You miss this connection. Time is 11:00 while this edge leaves at 10:59 from Zurich, Meierhofplatz to Zurich, Honggerberg\n",
      "Delay of 5.98492672926 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "Delay of 6.95754067587 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "Delay of 10.6905613184 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "You miss this connection. Time is 10:59 while this edge leaves at 10:59 from Zurich, Meierhofplatz to Zurich, Honggerberg\n",
      "Delay of 7.91628094819 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "Delay of 13.2514679383 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "You miss this connection. Time is 11:02 while this edge leaves at 10:59 from Zurich, Meierhofplatz to Zurich, Honggerberg\n",
      "Delay of 2.67950505992 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "Delay of 11.4306517984 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "You miss this connection. Time is 11:00 while this edge leaves at 10:59 from Zurich, Meierhofplatz to Zurich, Honggerberg\n",
      "Delay of 7.64471138187 for Zurich, Schwert to Zurich, Meierhofplatz\n",
      "0.6"
     ]
    }
   ],
   "source": [
    "# Test pour voir si on peut rater une connection: \n",
    "test = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591122', confidence=0.98, durations_dicts=durations_dicts)\n",
    "test['mean'][10] = 6\n",
    "test['std'][10] = 4\n",
    "validate_path_(test, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create duration dictionnaries if needed\n",
    "\n",
    "Code commented, don't have the permission to **change** a file, can write if put another path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durations_dicts = {}\n",
    "edge_and_data_tuple = zip(graph.edges(keys=True),\n",
    "              map(lambda x: x[2], graph.edges(data=True)))\n",
    "edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "for c in [0.25, 0.5, 0.75, 0.9, 0.95, 0.98, 0.99]:\n",
    "    durations_dicts[c] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                            data['std'], \n",
    "                                                                                            c)\n",
    "                                       if data['mean'] != None and data['std'] != None\n",
    "                                       else data['duration']\n",
    "                                      } for e, data in edge_and_data_tuple}\n",
    "    \n",
    "\"\"\" Conversion to json \"\"\"\n",
    "durations_dicts_for_json = {}\n",
    "for c in durations_dicts.keys():\n",
    "    durations_dicts_for_json[c] = {str(k): v for k, v in durations_dicts[c].items()}\n",
    "\n",
    "print('Length of json:', len(json.dumps(durations_dicts_for_json))) -> 30106955\n",
    "\n",
    "\"\"\" Save to hdfs \"\"\"\n",
    "sc.parallelize([json.dumps(durations_dicts_for_json)]).coalesce(1).saveAsTextFile('/user/{}/durations_for_confidence_.json'.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edges_for_trip(edges_df, day_id, arrival_time):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    min_dep_time = arrival_time - 60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_time))\n",
    "    \n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time']),\n",
    "                                                                       'trip_id': r['trip_id'],\n",
    "                                                                       'mean': r['mean'],\n",
    "                                                                       'std': r['std']})).collect()\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, arrival_hour*60+arrival_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 nodes removed"
     ]
    }
   ],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)\n",
    "\n",
    "old_number_of_nodes = graph.number_of_nodes()\n",
    "# Remove unreachable nodes\n",
    "dists, paths = normal_dijkstra(graph, '8503000')\n",
    "not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "_ = graph.remove_nodes_from(list(not_reachable))\n",
    "print('{} nodes removed'.format(old_number_of_nodes - graph.number_of_nodes()))\n",
    "\n",
    "# Temp for problem of name's encoding\n",
    "import unicodedata\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without minimum confidence ->\n",
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049) in 29.00 minutes, departure at 10:30\n",
      "             from         from_id              to           to_id  duration  total_duration departure_time   walk no_change mean_std_null\n",
      "0       Zurich HB         8503000       Zurich HB  8503000:0:4...  2.135259        2.135259          10:30   True     False          True\n",
      "1       Zurich HB  8503000:0:4...  Zurich Hard...     8503020:0:3  2.000000        9.000000          10:37  False     False         False\n",
      "2  Zurich Hard...     8503020:0:3  Zurich Oerl...     8503006:0:8  5.000000       14.000000          10:39  False      True         False\n",
      "3  Zurich Oerl...     8503006:0:8      Glattbrugg     8503310:0:3  2.000000       17.000000          10:45  False      True         False\n",
      "4      Glattbrugg     8503310:0:3  Glattbrugg,...         8590620  3.063448       20.063448          10:47   True     False          True\n",
      "5  Glattbrugg,...         8590620  Glattbrugg,...         8590626  1.000000       24.000000          10:53  False     False         False\n",
      "6  Glattbrugg,...         8590626  Glattpark, ...         8591830  2.000000       26.000000          10:54  False      True         False\n",
      "7  Glattpark, ...         8591830  Zurich, Fer...         8591128  1.000000       27.000000          10:56  False      True         False\n",
      "8  Zurich, Fer...         8591128  Zurich, Auzelg         8591049  2.000000       29.000000          10:57  False      True         False\n",
      "\n",
      "With minimum confidence ->\n",
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049) in 29.00 minutes, departure at 10:30\n",
      "             from         from_id              to           to_id  duration  total_duration departure_time   walk no_change mean_std_null\n",
      "0       Zurich HB         8503000       Zurich HB  8503000:0:4...  2.135259        2.135259          10:30   True     False          True\n",
      "1       Zurich HB  8503000:0:4...  Zurich Hard...     8503020:0:3  2.000000        9.000000          10:37  False     False         False\n",
      "2  Zurich Hard...     8503020:0:3  Zurich Oerl...     8503006:0:8  5.000000       14.000000          10:39  False      True         False\n",
      "3  Zurich Oerl...     8503006:0:8      Glattbrugg     8503310:0:3  2.000000       17.000000          10:45  False      True         False\n",
      "4      Glattbrugg     8503310:0:3  Glattbrugg,...         8590620  3.063448       20.063448          10:47   True     False          True\n",
      "5  Glattbrugg,...         8590620  Glattbrugg,...         8590626  1.000000       24.000000          10:53  False     False         False\n",
      "6  Glattbrugg,...         8590626  Glattpark, ...         8591830  2.000000       26.000000          10:54  False      True         False\n",
      "7  Glattpark, ...         8591830  Zurich, Fer...         8591128  1.000000       27.000000          10:56  False      True         False\n",
      "8  Zurich, Fer...         8591128  Zurich, Auzelg         8591049  2.000000       29.000000          10:57  False      True         False"
     ]
    }
   ],
   "source": [
    "# Tao's example (except for the departure time)\n",
    "print('Without minimum confidence ->')\n",
    "best_path1 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049',confidence = 0.98, durations_dicts=durations_dicts)\n",
    "print('\\nWith minimum confidence ->')\n",
    "best_path2 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049', confidence=0.98, durations_dicts=durations_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without minimum confidence ->\n",
      "Going from Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057) in 17.14 minutes, departure at 10:30\n",
      "             from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null\n",
      "0  Zurich, Tri...  8503610  Zurich, In ...  8591214  1.000000        2.000000          10:31  False     False         False\n",
      "1  Zurich, In ...  8591214  Zurich, Gol...  8591163  1.000000        3.000000          10:32  False      True         False\n",
      "2  Zurich, Gol...  8591163  Zurich, Alb...  8591036  2.000000        5.000000          10:33  False      True         False\n",
      "3  Zurich, Alb...  8591036  Zurich, Alb...  8591037  0.000000        5.000000          10:35  False      True         False\n",
      "4  Zurich, Alb...  8591037  Zurich, Unt...  8591408  2.000000        7.000000          10:35  False      True         False\n",
      "5  Zurich, Unt...  8591408  Zurich, Rau...  8591311  1.000000        8.000000          10:37  False      True         False\n",
      "6  Zurich, Rau...  8591311  Zurich, Lin...  8591258  2.000000       10.000000          10:38  False      True         False\n",
      "7  Zurich, Lin...  8591258  Zurich, Bri...  8591097  1.000000       11.000000          10:40  False      True         False\n",
      "8  Zurich, Bri...  8591097  Zurich Alts...  8591056  1.000000       12.000000          10:41  False      True         False\n",
      "9  Zurich Alts...  8591056  Zurich Alts...  8591057  5.143597       17.143597          10:42   True     False          True\n",
      "\n",
      "With minimum confidence ->\n",
      "Going from Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057) in 17.47 minutes, departure at 10:30\n",
      "             from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null\n",
      "0  Zurich, Tri...  8503610  Zurich, In ...  8591214  1.000000        2.000000          10:31  False     False         False\n",
      "1  Zurich, In ...  8591214  Zurich, Gol...  8591163  1.000000        3.000000          10:32  False      True         False\n",
      "2  Zurich, Gol...  8591163  Zurich, Alb...  8591036  2.000000        5.000000          10:33  False      True         False\n",
      "3  Zurich, Alb...  8591036  Zurich, Alb...  8591037  0.000000        5.000000          10:35  False      True         False\n",
      "4  Zurich, Alb...  8591037  Zurich, Unt...  8591408  2.000000        7.000000          10:35  False      True         False\n",
      "5  Zurich, Unt...  8591408  Zurich, Rau...  8591311  1.000000        8.000000          10:37  False      True         False\n",
      "6  Zurich, Rau...  8591311  Zurich, Lin...  8591258  2.000000       10.000000          10:38  False      True         False\n",
      "7  Zurich, Lin...  8591258  Zurich, Bri...  8591097  1.000000       11.000000          10:40  False      True         False\n",
      "8  Zurich, Bri...  8591097  Zurich Alts...  8591056  1.000000       12.000000          10:41  False      True         False\n",
      "9  Zurich Alts...  8591056  Zurich Alts...  8591057  5.143597       17.474037          10:42   True     False          True"
     ]
    }
   ],
   "source": [
    "# From Triemli to Altstetten\n",
    "print('Without minimum confidence ->')\n",
    "best_path1 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057')\n",
    "print('\\nWith minimum confidence ->')\n",
    "best_path2 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057', confidence=0.95, durations_dicts=durations_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration': 2.0, 'std': 1.05697167217, 'time': 682.0, 'trip_id': u'234.TA.26-15-j19-1.41.H', 'mean': 0.27319172912666667}"
     ]
    }
   ],
   "source": [
    "# Weird attributes?\n",
    "print(graph.get_edge_data('8503000:0:41/42', '8503020:0:3', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046632828786368166"
     ]
    }
   ],
   "source": [
    "# Proportion of null mean or std in non-walking edges\n",
    "(len(filter(lambda x: x[2]['mean'] == None or x[2]['std'] == None, filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True))))\n",
    " / float(len(filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
