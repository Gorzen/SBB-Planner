{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run:\n",
    "Only notebook to run ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'pyFiles': ['/user/gottraux/dijkstra_algorithms.py'], 'conf': {'spark.app.name': 'dslab-group_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7994</td><td>application_1589299642358_2517</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2517/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2517_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8044</td><td>application_1589299642358_2564</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2564/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2564_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8063</td><td>application_1589299642358_2587</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2587/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2587_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8066</td><td>application_1589299642358_2590</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_2590\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster067.iccluster.epfl.ch:45454/container_e06_1589299642358_2590_01_000001/container_e06_1589299642358_2590_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8082</td><td>application_1589299642358_2606</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2606/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2606_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8089</td><td>application_1589299642358_2613</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2613/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2613_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8091</td><td>application_1589299642358_2615</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2615/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2615_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8093</td><td>application_1589299642358_2617</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2617/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2617_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8095</td><td>application_1589299642358_2619</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2619/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2619_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8097</td><td>application_1589299642358_2621</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2621/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2621_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8098</td><td>application_1589299642358_2622</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2622/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2622_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8100</td><td>application_1589299642358_2624</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2624/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2624_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8101</td><td>application_1589299642358_2625</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2625/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2625_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8102</td><td>application_1589299642358_2626</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2626/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2626_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8103</td><td>application_1589299642358_2627</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2627/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2627_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8107</td><td>application_1589299642358_2631</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2631/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2631_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8108</td><td>application_1589299642358_2632</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2632/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2632_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8110</td><td>application_1589299642358_2635</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2635/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2635_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8112</td><td>application_1589299642358_2637</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2637/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2637_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8114</td><td>application_1589299642358_2639</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2639/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2639_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8116</td><td>application_1589299642358_2641</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2641/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2641_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8117</td><td>application_1589299642358_2642</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2642/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2642_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8119</td><td>application_1589299642358_2644</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2644/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2644_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8121</td><td>application_1589299642358_2646</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2646/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2646_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8122</td><td>application_1589299642358_2647</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2647/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2647_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8124</td><td>application_1589299642358_2649</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2649/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2649_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8126</td><td>application_1589299642358_2651</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2651/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2651_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8127</td><td>application_1589299642358_2652</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2652/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2652_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8128</td><td>application_1589299642358_2653</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2653/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2653_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8129</td><td>application_1589299642358_2654</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2654/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2654_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8130</td><td>application_1589299642358_2655</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2655/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2655_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8131</td><td>application_1589299642358_2656</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2656/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2656_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8132</td><td>application_1589299642358_2657</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2657/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2657_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8133</td><td>application_1589299642358_2658</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2658/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2658_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8134</td><td>application_1589299642358_2659</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2659/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2659_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8135</td><td>application_1589299642358_2660</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2660/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2660_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8137</td><td>application_1589299642358_2662</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2662/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2662_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8138</td><td>application_1589299642358_2663</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2663/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2663_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8139</td><td>application_1589299642358_2664</td><td>pyspark</td><td>starting</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2664/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2664_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"pyFiles\": [\"/user/gottraux/dijkstra_algorithms.py\"],\n",
    " \"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8140</td><td>application_1589299642358_2665</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2665/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2665_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\"\"\"\n",
    "To load (or reload) into hdfs:\n",
    "hdfs dfs -rm /user/${JUPYTERHUB_USER}/dijkstra_algorithms.py 2>/dev/null\n",
    "hdfs dfs -copyFromLocal notebooks/dijkstra_algorithms.py /user/${JUPYTERHUB_USER}/\n",
    "\"\"\"\n",
    "from dijkstra_algorithms import *\n",
    "\n",
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import pandas as pd\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "#username = 'gottraux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges_with_mean_and_std_sec.orc\".format(username))\n",
    "\n",
    "#durations_dicts = json.loads(sc.textFile('/user/{}/durations_for_confidence_.json'.format(username)).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_times = pd.read_pickle('walking_edges.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'walking_times' as 'walking_times' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reverse edges\n",
    "#edges_walking = (walking_times.withColumnRenamed('source', 'temp')\n",
    "#                 .withColumnRenamed('target', 'source')\n",
    "#                 .withColumnRenamed('temp', 'target').toPandas())\n",
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['walk_duration']}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove dics from dijkstra time for the moment and make it return the mean and std as well because we need it to validate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dijkstra_with_time(G, first_source, arrival_time, last_target, confidence=None, \n",
    "                       confidence_step=0.01, durations_dicts=None, paths=None, departure_time = None):\n",
    "    G = G.copy()\n",
    "    #departure_time = arrival_time - MAX_TRIP_DURATION*60\n",
    "    departure_time = departure_time\n",
    "    while True:\n",
    "        \"\"\"\n",
    "        # Update durations according to confidence\n",
    "        if confidence != None:\n",
    "            if durations_dicts == None:\n",
    "                raise ValueError('You must pass durations_dicts for the confidence.')\n",
    "            # Load dict with modifications\n",
    "            if confidence not in durations_dicts:\n",
    "                edge_and_data_tuple = zip(G.edges(keys=True), \n",
    "                              map(lambda x: x[2], G.edges(data=True)))\n",
    "                edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "                durations_dicts[confidence] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                                        data['std'], \n",
    "                                                                                                        confidence)\n",
    "                                                   if data['mean'] != None and data['std'] != None\n",
    "                                                   else data['duration']\n",
    "                                                  } for e, data in edge_and_data_tuple}\n",
    "            \n",
    "            # Update graph\n",
    "            nx.set_edge_attributes(G, durations_dicts[confidence])\n",
    "        \"\"\"\n",
    "        \n",
    "        if not G.is_directed():\n",
    "            raise ValueError('Input graph is not directed while it should be.')\n",
    "\n",
    "        G_succ = G.succ \n",
    "        \n",
    "        # paths stores the nodes in dijkstra's shortest path\n",
    "        paths = {first_source: [first_source]}\n",
    "        \n",
    "        # stores the edges in dijkstra's shortest path\n",
    "        e_paths = {first_source: []}\n",
    "        \n",
    "        # dictionary of final distances to nodes\n",
    "        dist = {}  \n",
    "        \n",
    "        # dictionnary of whether it's the first time a node is visited\n",
    "        seen = {first_source: departure_time}\n",
    "\n",
    "        # use heapq with (distance,label) tuples\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "        c = count()\n",
    "        fringe = []  \n",
    "        \n",
    "        # push the source as the first node on the heap\n",
    "        push(fringe, (departure_time, next(c), first_source))\n",
    "\n",
    "        # while heap not empty\n",
    "        while fringe:\n",
    "            \n",
    "            # take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "\n",
    "            # check if node has already been looked at and has a final shortest distance: \n",
    "            if source in dist:\n",
    "                continue  # already searched this node so go to another\n",
    "\n",
    "            # take the distance to the node from the heap \n",
    "            # source starts with distance = departure_time\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the source is the last_target. \n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:\n",
    "                    \n",
    "                    # Check if walking edge: \n",
    "                    # walking edges have a departure time of -1\n",
    "                    dep_time_edge = G.get_edge_data(source, target, edge_id)['time']\n",
    "                    \n",
    "                    if dep_time_edge == -1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        # set the departure time to the distance to that node as we can leave immediatly\n",
    "                        dep_time_edge = d\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = G.get_edge_data(source, target, edge_id)['trip_id']\n",
    "                        \n",
    "                    # take only edges that have a departure time bigger \n",
    "                    # than the time it takes to get to the node\n",
    "                    if dep_time_edge < dist[source]:\n",
    "                       # move on to next edge if it's earlier \n",
    "                        continue\n",
    "                        \n",
    "                    # Check if edge is feasible (also accoring to confidence)\n",
    "                    # Check if last edge taken was not a walking edge\n",
    "                    # Check if there is at least a path of length 1 to the source node \n",
    "                    # (e.g. that this node is not the original source)\n",
    "                    if len(e_paths[source]) >= 1 and not e_paths[source][-1][2]['walk']:\n",
    "                        last_edge_source, last_edge_target, last_edge_info = e_paths[source][-1]\n",
    "                        last_delay = compute_delay_uncertainty(last_edge_info['mean'], \n",
    "                                                                   last_edge_info['std'], \n",
    "                                                                   confidence)\n",
    "                        # If we make a transport-> walk change\n",
    "                        if walking_edge:\n",
    "                            # add delay to departure time of walk as we will leave later\n",
    "                            dep_time_edge += last_delay\n",
    "                        else:\n",
    "                            # If we make a transport->transport change, check if we have time to change\n",
    "                            # To change we need that the next connection leaves >= 2 min + delay of transport\n",
    "                            # If not we cannot take that edge\n",
    "                            if current_trip_id != last_edge_info['trip_id']\\\n",
    "                            and dep_time_edge < dist[source] + 2 + last_delay:\n",
    "                                continue\n",
    "\n",
    "                    # Get the duration between two nodes:\n",
    "                    duration_cost = G.get_edge_data(source, target, edge_id)['duration']\n",
    "                    \n",
    "                    if duration_cost is None:\n",
    "                            raise ValueError('Edge without a duration.')\n",
    "\n",
    "                    # Add the weight to the current distance to a node\n",
    "                    current_dist = dep_time_edge + duration_cost\n",
    "\n",
    "                    # if target has already been visited once and has a final distance:\n",
    "                    if target in dist:\n",
    "                            # if we find a distance smaller than the actual distance in dic\n",
    "                            # raise error because dic distances contains only final distances\n",
    "                            if current_dist < dist[target]:\n",
    "                                raise ValueError('Contradictory paths found:',\n",
    "                                                     'negative weights?')\n",
    "\n",
    "                    # either node has been seen before or the current distance is smaller than the \n",
    "                    # proposed distance in seen[target]:\n",
    "                    elif target not in seen or current_dist < seen[target]:\n",
    "                        # update the seen distance\n",
    "                        seen[target] = current_dist\n",
    "                        # push it onto the heap so that we will look at its descendants later\n",
    "                        push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                        # update the paths till target:\n",
    "                        if paths is not None:\n",
    "                            edge_dict = G.get_edge_data(source, target, edge_id)\n",
    "                            \n",
    "                            edge_dict['walk'] = walking_edge\n",
    "                            edge_dict['departure_time'] = dep_time_edge\n",
    "                            \n",
    "                            e_paths[target] = e_paths[source] + [(source, target, edge_dict)]\n",
    "\n",
    "\n",
    "        # If there is no path to the last_target:\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                         'departure_time', 'walk', 'no_change', 'mean_std_null','mean','std'])\n",
    "\n",
    "        \n",
    "        # Validation: \n",
    "        if confidence == None or validate_path(e_paths[last_target], confidence, G):\n",
    "            break\n",
    "        else:\n",
    "            # else increase confidence by a confidence step and start again: \n",
    "            confidence += confidence_step\n",
    "            \n",
    "    # Path validated\n",
    "    if paths is not None:\n",
    "        nodes_data = G.nodes(data=True)\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        best_path = e_paths[last_target]\n",
    "        departure_string = minute_to_string(best_path[0][2]['departure_time'])\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                                      first_source,\n",
    "                                                                                      nodes_data[last_target]['name'],\n",
    "                                                                                      last_target, \n",
    "                                                                                      dist[last_target] - departure_time,\n",
    "                                                                                      minute_to_string(departure_time)))\n",
    "        \n",
    "        # Construct best path's data structure\n",
    "        best_path_df = pd.DataFrame(columns=['from', 'from_id', 'to', 'to_id', 'duration', 'total_duration',\n",
    "                                          'departure_time', 'walk', 'no_change', 'mean_std_null', 'mean','std'])\n",
    "        last_edge_info = False\n",
    "        for source, target, edge_info in best_path:\n",
    "            no_change = ('trip_id' in edge_info                                   # We're in a transport\n",
    "                         and last_edge_info and 'trip_id' in last_edge_info       # and last edge also\n",
    "                         and last_edge_info['trip_id'] == edge_info['trip_id'])   # and same trip_id\n",
    "            mean_std_null = 'trip_id' in edge_info and 'mean' not in edge_info or 'std' not in edge_info\n",
    "            \n",
    "            if not mean_std_null:\n",
    "                mean = edge_info['mean']\n",
    "                std = edge_info['std']\n",
    "                if  edge_info['mean'] == None or  edge_info['std'] == None: \n",
    "                    mean = edge_info['duration']\n",
    "                    std = 0\n",
    "            if 'mean' not in edge_info or 'std' not in edge_info:\n",
    "                mean = edge_info['duration']\n",
    "                std = 0\n",
    "                \n",
    "            \n",
    "            current_path_dict = {'from': nodes_data[source]['name'],\n",
    "                                 'from_id': source, \n",
    "                                 'to': nodes_data[target]['name'], \n",
    "                                 'to_id': target, \n",
    "                                 'duration': edge_info['duration'], \n",
    "                                 'total_duration': dist[target] - departure_time,\n",
    "                                 'departure_time': minute_to_string(edge_info['departure_time']), \n",
    "                                 'walk':edge_info['walk'], \n",
    "                                 'no_change': no_change, \n",
    "                                 'mean_std_null': mean_std_null,\n",
    "                                'mean':mean,\n",
    "                                'std':std}\n",
    "            best_path_df = best_path_df.append(current_path_dict, ignore_index=True)\n",
    "            last_edge_info = edge_info\n",
    "        \n",
    "        with pd.option_context('display.max_rows', None, \n",
    "                               'display.max_columns', None, \n",
    "                               'display.max_colwidth', 15,\n",
    "                               'display.expand_frame_repr', False):\n",
    "            print(best_path_df)\n",
    "        return best_path_df\n",
    "    raise ValueError('Should not be here')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrival time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 630)\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 32.00 minutes, departure at 10:30\n",
      "              from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean       std\n",
      "0        Zurich HB  8503000  Zurich, Bah...  8587349  4.704125        4.704125          10:30   True     False          True  4.704125         0\n",
      "1   Zurich, Bah...  8587349  Zurich, Sta...  8591379  1.000000        7.000000          10:36  False     False         False  1.918103    1.3509\n",
      "2   Zurich, Sta...  8591379  Zurich, Nor...  8591291  3.000000       10.000000          10:37  False      True         False  1.183184   1.15276\n",
      "3   Zurich, Nor...  8591291  Zurich, Let...  8591251  1.000000       11.000000          10:40  False      True         False  1.297521   1.28782\n",
      "4   Zurich, Let...  8591251  Zurich Wipk...  8591066  1.000000       12.000000          10:41  False      True         False  1.255934   1.03589\n",
      "5   Zurich Wipk...  8591066  Zurich, Ros...  8591323  2.000000       14.000000          10:42  False      True         False  1.490386   1.74922\n",
      "6   Zurich, Ros...  8591323  Zurich, Leh...  8591247  1.000000       15.000000          10:44  False      True         False  1.389154   1.77222\n",
      "7   Zurich, Leh...  8591247  Zurich, Reb...  8591312  1.000000       16.000000          10:45  False      True         False  1.231264   1.10861\n",
      "8   Zurich, Reb...  8591312  Zurich, Kem...  8591226  1.000000       17.000000          10:46  False      True         False  1.246333   1.11333\n",
      "9   Zurich, Kem...  8591226  Zurich, Sch...  8591353  1.000000       18.000000          10:47  False      True         False  1.229301   1.09003\n",
      "10  Zurich, Sch...  8591353  Zurich, Mei...  8576240  1.000000       19.000000          10:48  False      True         False  1.066935  0.976204\n",
      "11  Zurich, Mei...  8576240  Zurich, Hon...  8591201  1.000000       30.000000          10:59  False     False         False  1.157511   1.10584\n",
      "12  Zurich, Hon...  8591201  Zurich, ETH...  8591122  2.000000       32.000000          11:00  False      True         False  1.026429   1.54772"
     ]
    }
   ],
   "source": [
    "source = '8503000'\n",
    "target = '8591122'\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "\n",
    "arrival_time = arrival_hour*60+arrival_minute\n",
    "\n",
    "#start with two hours before:\n",
    "dep = arrival_time - MAX_TRIP_DURATION*60\n",
    "\n",
    "print(arrival_time, dep)\n",
    "\n",
    "path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, last_target=target, confidence=0.98, departure_time = dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convertToMinute(s):\n",
    "    h, m = s.split(':')\n",
    "    h,m = int(h), int(m)\n",
    "    \n",
    "    return h*60+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with 88.0 minutes difference\n",
      "Trip takes 32.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 28.00 minutes, departure at 11:48\n",
      "              from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean       std\n",
      "0        Zurich HB  8503000  Zurich, Sta...  8591379  7.594058        7.594058          11:48   True     False          True  7.594058         0\n",
      "1   Zurich, Sta...  8591379  Zurich, Bec...  8591071  1.000000        9.000000          11:56  False     False         False  0.929633   1.35262\n",
      "2   Zurich, Bec...  8591071  Zurich, Kro...  8591237  2.000000       11.000000          11:57  False      True         False  0.815931   1.39031\n",
      "3   Zurich, Kro...  8591237  Zurich, Sch...  8591335  1.000000       12.000000          11:59  False      True         False  0.848701    1.4317\n",
      "4   Zurich, Sch...  8591335  Zurich, Lau...  8591246  1.000000       13.000000          12:00  False      True         False  0.875579   3.47334\n",
      "5   Zurich, Lau...  8591246  Zurich, Buc...  8591101  1.000000       14.000000          12:01  False      True         False  1.043134   4.14367\n",
      "6   Zurich, Buc...  8591101  Zurich, Wei...  8591425  2.000000       22.000000          12:08  False     False         False  1.270496   1.41239\n",
      "7   Zurich, Wei...  8591425  Zurich, Wai...  8591419  1.000000       23.000000          12:10  False      True         False  0.875809  0.794958\n",
      "8   Zurich, Wai...  8591419  Zurich, Pfl...  8591302  1.000000       24.000000          12:11  False      True         False  0.840270  0.879329\n",
      "9   Zurich, Pfl...  8591302  Zurich, Wai...  8591416  1.000000       25.000000          12:12  False      True         False  0.958311  0.881041\n",
      "10  Zurich, Wai...  8591416  Zurich, Im ...  8591213  1.000000       26.000000          12:13  False      True         False  0.918484  0.862683\n",
      "11  Zurich, Im ...  8591213  Zurich, Hon...  8591201  1.000000       27.000000          12:14  False      True         False  0.800113  0.826628\n",
      "12  Zurich, Hon...  8591201  Zurich, ETH...  8591122  1.000000       28.000000          12:15  False      True         False  1.048723   1.23969"
     ]
    }
   ],
   "source": [
    "num_edges = len(path['total_duration'])\n",
    "duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "arrival_diff = arrival_time - first_arrival\n",
    "\n",
    "print('Start with {} minutes difference'.format(arrival_diff))\n",
    "print('Trip takes {} minutes'.format(duration))\n",
    "\n",
    "new_dep = arrival_time - duration - 10\n",
    "\n",
    "path2 = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                           last_target=target, confidence=0.98, departure_time = new_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now with 12.0 minutes difference\n",
      "Trip takes 21.0 minutes"
     ]
    }
   ],
   "source": [
    "num_edges = len(path2['total_duration'])\n",
    "\n",
    "duration = path2['total_duration'][num_edges-1]\n",
    "\n",
    "first_arrival = convertToMinute(path2['departure_time'][num_edges-1]) + path2['duration'][num_edges-1]\n",
    "arrival_diff = arrival_time - first_arrival\n",
    "\n",
    "print('Now with {} minutes difference'.format(arrival_diff))\n",
    "print('Trip takes {} minutes'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 21.00 minutes, departure at 11:57\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:57   True     False          True   9.300864   0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  11.000000       21.000000          12:07  False     False         False  11.000000   0"
     ]
    }
   ],
   "source": [
    "new_dep = arrival_time - duration - 5\n",
    "\n",
    "path3 = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                           last_target=target, confidence=0.98, departure_time = new_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now with 12.0 minutes difference\n",
      "Trip takes 21.0 minutes"
     ]
    }
   ],
   "source": [
    "num_edges = len(path3['total_duration'])\n",
    "\n",
    "duration = path3['total_duration'][num_edges-1]\n",
    "\n",
    "first_arrival = convertToMinute(path3['departure_time'][num_edges-1]) + path3['duration'][num_edges-1]\n",
    "arrival_diff = arrival_time - first_arrival\n",
    "\n",
    "print('Now with {} minutes difference'.format(arrival_diff))\n",
    "print('Trip takes {} minutes'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 32.00 minutes, departure at 10:30\n",
      "              from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean       std\n",
      "0        Zurich HB  8503000  Zurich, Bah...  8587349  4.704125        4.704125          10:30   True     False          True  4.704125         0\n",
      "1   Zurich, Bah...  8587349  Zurich, Sta...  8591379  1.000000        7.000000          10:36  False     False         False  1.918103    1.3509\n",
      "2   Zurich, Sta...  8591379  Zurich, Nor...  8591291  3.000000       10.000000          10:37  False      True         False  1.183184   1.15276\n",
      "3   Zurich, Nor...  8591291  Zurich, Let...  8591251  1.000000       11.000000          10:40  False      True         False  1.297521   1.28782\n",
      "4   Zurich, Let...  8591251  Zurich Wipk...  8591066  1.000000       12.000000          10:41  False      True         False  1.255934   1.03589\n",
      "5   Zurich Wipk...  8591066  Zurich, Ros...  8591323  2.000000       14.000000          10:42  False      True         False  1.490386   1.74922\n",
      "6   Zurich, Ros...  8591323  Zurich, Leh...  8591247  1.000000       15.000000          10:44  False      True         False  1.389154   1.77222\n",
      "7   Zurich, Leh...  8591247  Zurich, Reb...  8591312  1.000000       16.000000          10:45  False      True         False  1.231264   1.10861\n",
      "8   Zurich, Reb...  8591312  Zurich, Kem...  8591226  1.000000       17.000000          10:46  False      True         False  1.246333   1.11333\n",
      "9   Zurich, Kem...  8591226  Zurich, Sch...  8591353  1.000000       18.000000          10:47  False      True         False  1.229301   1.09003\n",
      "10  Zurich, Sch...  8591353  Zurich, Mei...  8576240  1.000000       19.000000          10:48  False      True         False  1.066935  0.976204\n",
      "11  Zurich, Mei...  8576240  Zurich, Hon...  8591201  1.000000       30.000000          10:59  False     False         False  1.157511   1.10584\n",
      "12  Zurich, Hon...  8591201  Zurich, ETH...  8591122  2.000000       32.000000          11:00  False      True         False  1.026429   1.54772\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 28.00 minutes, departure at 11:48\n",
      "              from  from_id              to    to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean       std\n",
      "0        Zurich HB  8503000  Zurich, Sta...  8591379  7.594058        7.594058          11:48   True     False          True  7.594058         0\n",
      "1   Zurich, Sta...  8591379  Zurich, Bec...  8591071  1.000000        9.000000          11:56  False     False         False  0.929633   1.35262\n",
      "2   Zurich, Bec...  8591071  Zurich, Kro...  8591237  2.000000       11.000000          11:57  False      True         False  0.815931   1.39031\n",
      "3   Zurich, Kro...  8591237  Zurich, Sch...  8591335  1.000000       12.000000          11:59  False      True         False  0.848701    1.4317\n",
      "4   Zurich, Sch...  8591335  Zurich, Lau...  8591246  1.000000       13.000000          12:00  False      True         False  0.875579   3.47334\n",
      "5   Zurich, Lau...  8591246  Zurich, Buc...  8591101  1.000000       14.000000          12:01  False      True         False  1.043134   4.14367\n",
      "6   Zurich, Buc...  8591101  Zurich, Wei...  8591425  2.000000       22.000000          12:08  False     False         False  1.270496   1.41239\n",
      "7   Zurich, Wei...  8591425  Zurich, Wai...  8591419  1.000000       23.000000          12:10  False      True         False  0.875809  0.794958\n",
      "8   Zurich, Wai...  8591419  Zurich, Pfl...  8591302  1.000000       24.000000          12:11  False      True         False  0.840270  0.879329\n",
      "9   Zurich, Pfl...  8591302  Zurich, Wai...  8591416  1.000000       25.000000          12:12  False      True         False  0.958311  0.881041\n",
      "10  Zurich, Wai...  8591416  Zurich, Im ...  8591213  1.000000       26.000000          12:13  False      True         False  0.918484  0.862683\n",
      "11  Zurich, Im ...  8591213  Zurich, Hon...  8591201  1.000000       27.000000          12:14  False      True         False  0.800113  0.826628\n",
      "12  Zurich, Hon...  8591201  Zurich, ETH...  8591122  1.000000       28.000000          12:15  False      True         False  1.048723   1.23969\n",
      "Start with 14.0 minutes difference\n",
      "Trip takes 28.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 21.00 minutes, departure at 11:57\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:57   True     False          True   9.300864   0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  11.000000       21.000000          12:07  False     False         False  11.000000   0\n",
      "Start with 12.0 minutes difference\n",
      "Trip takes 21.0 minutes\n",
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 50.87 minutes, departure at 12:07\n",
      "              from       from_id              to         to_id  duration  total_duration departure_time   walk no_change mean_std_null      mean      std\n",
      "0        Zurich HB       8503000       Zurich HB  8503000:0:34  3.893616        3.893616          12:07   True     False          True  3.893616        0\n",
      "1        Zurich HB  8503000:0:34  Zurich Oerl...   8503006:0:2  4.000000        9.000000          12:12  False     False         False  0.336499  1.09469\n",
      "2   Zurich Oerl...   8503006:0:2  Zurich Oerl...       8580449  3.139618       12.466253          12:16   True     False          True  3.139618        0\n",
      "3   Zurich Oerl...       8580449  Zurich, Reg...       8591314  2.000000       16.000000          12:21  False     False         False  1.042898  1.49167\n",
      "4   Zurich, Reg...       8591314  Zurich, Obe...       8591293  1.000000       20.000000          12:26  False     False         False  1.418078  8.55139\n",
      "5   Zurich, Obe...       8591293  Zurich, Neu...       8591285  1.000000       21.000000          12:27  False      True         False  1.782585  8.54084\n",
      "6   Zurich, Neu...       8591285  Zurich, Gla...       8591160  1.000000       22.000000          12:28  False      True         False  1.625981   6.1481\n",
      "7   Zurich, Gla...       8591160  Zurich, Ein...       8591118  2.000000       24.000000          12:29  False      True         False  1.504167  5.13464\n",
      "8   Zurich, Ein...       8591118  Zurich, Ler...       8591250  8.066215       33.598294          12:32   True     False          True  8.066215        0\n",
      "9   Zurich, Ler...       8591250  Zurich, Ler...       8591249  7.935674       41.533968          12:40   True     False          True  7.935674        0\n",
      "10  Zurich, Ler...       8591249  Zurich, ETH...       8591122  9.337519       50.871487          12:48   True     False          True  9.337519        0\n",
      "717.0"
     ]
    }
   ],
   "source": [
    "decrements = [10, 5, 2, 1, 0]\n",
    "source = '8503000'\n",
    "target = '8591122'\n",
    "day_id, arrival_hour, arrival_minute = 4, 12, 30\n",
    "\n",
    "arrival_time = arrival_hour*60+arrival_minute\n",
    "\n",
    "def depart_time(arrival_time, source, target, decrements):\n",
    "    #start with two hours before:\n",
    "    dep = arrival_time - MAX_TRIP_DURATION*60\n",
    "    path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = dep)\n",
    "    num_edges = len(path['total_duration'])\n",
    "    duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "    first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "    arrival_diff = arrival_time - first_arrival\n",
    "    \n",
    "    departures = [dep]\n",
    "    \n",
    "    if arrival_diff < 0:\n",
    "        raise ErrorValue('Arrives after wanted arrival time')\n",
    "    for i in decrements:\n",
    "        dep = arrival_time - duration - i\n",
    "        path = dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = dep)\n",
    "        num_edges = len(path['total_duration'])\n",
    "        duration = path['total_duration'][num_edges-1]\n",
    "\n",
    "        first_arrival = convertToMinute(path['departure_time'][num_edges-1]) + path['duration'][num_edges-1]\n",
    "        arrival_diff = arrival_time - first_arrival\n",
    "        \n",
    "        if arrival_diff < 0:\n",
    "            return departures[0]\n",
    "        \n",
    "        departures.insert(0, dep)\n",
    "\n",
    "        print('Start with {} minutes difference'.format(arrival_diff))\n",
    "        print('Trip takes {} minutes'.format(duration))\n",
    "\n",
    "        \n",
    "    return departures[0]\n",
    "\n",
    "dep = depart_time(arrival_time, source, target, decrements)\n",
    "dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, ETH Honggerberg (8591122) in 21.00 minutes, departure at 11:57\n",
      "             from  from_id              to    to_id   duration  total_duration departure_time   walk no_change mean_std_null       mean std\n",
      "0       Zurich HB  8503000  Zurich, Hal...  8591174   9.300864        9.300864          11:57   True     False          True   9.300864   0\n",
      "1  Zurich, Hal...  8591174  Zurich, ETH...  8591122  11.000000       21.000000          12:07  False     False         False  11.000000   0\n",
      "                from  from_id  ...       mean std\n",
      "0          Zurich HB  8503000  ...   9.300864   0\n",
      "1  Zurich, Haldenegg  8591174  ...  11.000000   0\n",
      "\n",
      "[2 rows x 12 columns]"
     ]
    }
   ],
   "source": [
    "dijkstra_with_time(graph, source, arrival_hour*60+arrival_minute, \n",
    "                               last_target=target, confidence=0.98, departure_time = 717.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation:\n",
    "\n",
    "##### Feasible paths:\n",
    "Create a function that looks through a path to see if it is valid. \n",
    "So it looks for:\n",
    "- missed connections\n",
    "- transfer time of less than 2 minutes between two transports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Returns true if there is time to take all edges, and if \n",
    "when chaning from a connection to another you have at least 2 minutes. \"\"\"\n",
    "\n",
    "def is_path_valid(path):\n",
    "    last_target = path['from_id'][len(path['from_id'])-1]\n",
    "    time = convertToMinute(path['departure_time'][0]) + path['duration'][0]\n",
    "    \n",
    "    for i in range(1, len(path['from_id'])):\n",
    "        #in case an edge taken actually left before we got there (only for transport edges, not for walks)\n",
    "        if not path['walk'][i] and convertToMinute(path['departure_time'][i]) < time:\n",
    "            print('You miss this connection. Time is {} while this edge leaves at {} from {} to {}'\\\n",
    "                  .format(minute_to_string(time), path['departure_time'][i], path['from'][i], path['to'][i]))\n",
    "            return False\n",
    "        \n",
    "        #in case of change type transport -> trasnport need 2 minutes transfer:\n",
    "        if not path['no_change'][i] and not path['walk'][i]:\n",
    "            if not path['walk'][i-1]:\n",
    "                if convertToMinute(path['departure_time'][i]) < time + 2:\n",
    "                    print('You do not have time to change to this connection between {} to {} leaving at {}. You arrive at {} and need at least 2 min transfer'\\\n",
    "                          .format(path['from'][i],path['to'][i], path['departure_time'][i], minute_to_string(time)))\n",
    "                    return False\n",
    "        \n",
    "        else: \n",
    "            time = convertToMinute(path['departure_time'][i]) + path['duration'][i]\n",
    "    return True\n",
    "\n",
    "# test of is path valid:\n",
    "#assert(is_path_valid(best_path1))\n",
    "#assert(is_path_valid(best_path2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate a path:\n",
    "Then for a given path, we sample felays for transfers where we go from a transport -> walk or transport -> transport. \n",
    "\n",
    "For transport 1 -> transport 2: the delay of transport 1 will be added to its trip duration\n",
    "For transport -> walk: the delay of transport will be added to the departure time of walk \n",
    "\n",
    "After modifying these values, we check whether the path is still feasible. We repeat this operation a ceertain number of times and report the percentage of feasible paths. \n",
    "\n",
    "For the moment, delays are sampled from an absolute normal distribution (**?good?**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_path_(path, confidence):\n",
    "    num_tries = 10\n",
    "    num_valids = 0\n",
    "    \n",
    "    for i in range(num_tries):\n",
    "        path_copy = path.copy()\n",
    "        for i in range(len(path['from_id'])):\n",
    "            #only for transfers etiher to other trains or to walking: \n",
    "            if i > 1 and not path['no_change'][i]:\n",
    "                mean = path['mean'][i-1]\n",
    "                std = path['std'][i-1]\n",
    "                #sample a delay:\n",
    "                #delay = compute_delay_uncertainty(mean, std, confidence)\n",
    "                \n",
    "                # calcluate delay for connection of before:\n",
    "                if std != 0:\n",
    "                    \n",
    "                    #delay = np.absolute(np.random.normal(mean, std))\n",
    "                    delay = np.random.normal(mean, std)\n",
    "                else: delay = 0\n",
    "                \n",
    "                # if its between two transports we just add it to trip duration:\n",
    "                if not path['walk'][i] and not path['walk'][i-1]:\n",
    "                    print('Delay of {} for {} to {}'.format(delay, path_copy['from'][i-1], path_copy['to'][i-1]))\n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                \n",
    "                # transfer from trans to walk:\n",
    "                if not path['walk'][i-1] and path['walk'][i]:\n",
    "                    # if a train to a walk is delayed, the walk needs to leave later:\n",
    "                    #need to leave at the time it takes for the delayed connection to arrive, \n",
    "                    # so if delayed need to start walking later: \n",
    "                    \n",
    "                    if delay !=0:\n",
    "                        print('Delay of {} for {} to {}, need to start walking later from {}'\\\n",
    "                                  .format(delay, path_copy['from'][i-1], path_copy['to'][i-1], path_copy['to'][i-1]))\n",
    "                    \n",
    "                    #add duration to transp: \n",
    "                    path_copy['duration'][i-1] += delay\n",
    "                    \n",
    "                    #delay the start of walk:\n",
    "                    arrival_of_edge_before = path_copy['duration'][i-1]+convertToMinute(path_copy['departure_time'][i-1])\n",
    "                    \n",
    "                    # need to start later:\n",
    "                    new_dep_time = minute_to_string(arrival_of_edge_before)\n",
    "                    path_copy['departure_time'][i] = new_dep_time\n",
    "        \n",
    "        if is_path_valid(path_copy):\n",
    "            num_valids += 1\n",
    "    return num_valids/float(num_tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pour voir si on peut rater une connection: \n",
    "test = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591122', confidence=0.98, durations_dicts=durations_dicts)\n",
    "test['mean'][10] = 6\n",
    "test['std'][10] = 4\n",
    "validate_path_(test, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create duration dictionnaries if needed\n",
    "\n",
    "Code commented, don't have the permission to **change** a file, can write if put another path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durations_dicts = {}\n",
    "edge_and_data_tuple = zip(graph.edges(keys=True),\n",
    "              map(lambda x: x[2], graph.edges(data=True)))\n",
    "edge_and_data_tuple = filter(lambda x: 'mean' in x[1] and 'std' in x[1], edge_and_data_tuple)\n",
    "for c in [0.25, 0.5, 0.75, 0.9, 0.95, 0.98, 0.99]:\n",
    "    durations_dicts[c] = {e: {'duration': data['mean'] + compute_delay_uncertainty(data['mean'], \n",
    "                                                                                            data['std'], \n",
    "                                                                                            c)\n",
    "                                       if data['mean'] != None and data['std'] != None\n",
    "                                       else data['duration']\n",
    "                                      } for e, data in edge_and_data_tuple}\n",
    "    \n",
    "\"\"\" Conversion to json \"\"\"\n",
    "durations_dicts_for_json = {}\n",
    "for c in durations_dicts.keys():\n",
    "    durations_dicts_for_json[c] = {str(k): v for k, v in durations_dicts[c].items()}\n",
    "\n",
    "print('Length of json:', len(json.dumps(durations_dicts_for_json))) -> 30106955\n",
    "\n",
    "\"\"\" Save to hdfs \"\"\"\n",
    "sc.parallelize([json.dumps(durations_dicts_for_json)]).coalesce(1).saveAsTextFile('/user/{}/durations_for_confidence_.json'.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edges_for_trip(edges_df, day_id, arrival_time):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    min_dep_time = arrival_time - 60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_time))\n",
    "    \n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time']),\n",
    "                                                                       'trip_id': r['trip_id'],\n",
    "                                                                       'mean': r['mean'],\n",
    "                                                                       'std': r['std']})).collect()\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, arrival_hour*60+arrival_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 nodes removed"
     ]
    }
   ],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)\n",
    "\n",
    "old_number_of_nodes = graph.number_of_nodes()\n",
    "# Remove unreachable nodes\n",
    "dists, paths = normal_dijkstra(graph, '8503000')\n",
    "not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "_ = graph.remove_nodes_from(list(not_reachable))\n",
    "print('{} nodes removed'.format(old_number_of_nodes - graph.number_of_nodes()))\n",
    "\n",
    "# Temp for problem of name's encoding\n",
    "import unicodedata\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tao's example (except for the departure time)\n",
    "print('Without minimum confidence ->')\n",
    "#best_path1 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049',confidence = 0.98, durations_dicts=durations_dicts)\n",
    "print('\\nWith minimum confidence ->')\n",
    "#best_path2 = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049', confidence=0.98, durations_dicts=durations_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Triemli to Altstetten\n",
    "print('Without minimum confidence ->')\n",
    "#best_path1 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057')\n",
    "print('\\nWith minimum confidence ->')\n",
    "#best_path2 = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057', confidence=0.95, durations_dicts=durations_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weird attributes?\n",
    "print(graph.get_edge_data('8503000:0:41/42', '8503020:0:3', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of null mean or std in non-walking edges\n",
    "(len(filter(lambda x: x[2]['mean'] == None or x[2]['std'] == None, filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True))))\n",
    " / float(len(filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
