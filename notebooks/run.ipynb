{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'dslab-group_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6966</td><td>application_1589299642358_1460</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1460/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1460_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6985</td><td>application_1589299642358_1479</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1479/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1479_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6990</td><td>application_1589299642358_1484</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1484/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1484_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6993</td><td>application_1589299642358_1487</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1487/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1487_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6995</td><td>application_1589299642358_1489</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1489/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1489_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6998</td><td>application_1589299642358_1492</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1492/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1492_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7000</td><td>application_1589299642358_1494</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1494/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1494_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7002</td><td>application_1589299642358_1496</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1496/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1496_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7003</td><td>application_1589299642358_1497</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1497/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1497_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7004</td><td>application_1589299642358_1498</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1498/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1498_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7005</td><td>application_1589299642358_1499</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1499/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1499_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7007</td><td>application_1589299642358_1501</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1501/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1501_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7008</td><td>application_1589299642358_1502</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1502/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1502_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7009</td><td>None</td><td>pyspark</td><td>starting</td><td></td><td></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}\n",
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')\n",
    "\n",
    "def minute_to_string(m):\n",
    "    hour, minute = m // 60, m - 60*(m//60)\n",
    "    time_string = '{:02}:{:02}'.format(int(hour), int(minute))\n",
    "    \n",
    "    return time_string\n",
    "\n",
    "def string_to_minute(s):\n",
    "    h, m, _ = s.split(':')\n",
    "    h,m = int(h), int(m)\n",
    "    \n",
    "    return h*60+m\n",
    "\n",
    "def get_time(graph, source, target, j):\n",
    "    attr = graph.edges[(source, target, j)]\n",
    "    return attr['time']\n",
    "\n",
    "def get_weight(graph, source, target, j):\n",
    "    attr = graph.edges[(source, target, j)]\n",
    "    return attr['duration']\n",
    "\n",
    "def normal_dijkstra(G, first_source, paths=None, cutoff=None, last_target=None):\n",
    "    \n",
    "    G_succ = G.succ if G.is_directed() else G.adj\n",
    "    paths = {first_source: [first_source]}\n",
    "\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    dist = {}  # dictionary of final distances\n",
    "    \n",
    "    # dictionnary of wthether it's the first time a node is visited\n",
    "    seen = {first_source: 0}\n",
    "\n",
    "    c = count()\n",
    "    fringe = []  # use heapq with (distance,label) tuples\n",
    "    push(fringe, (0, next(c), first_source))\n",
    "    \n",
    "    while fringe:\n",
    "        #take the node to look at: \n",
    "        (d, _, source) = pop(fringe)\n",
    "        \n",
    "        # check if node has already been looked at: \n",
    "        if source in dist:\n",
    "            continue  # already searched this node.\n",
    "        \n",
    "        # update the distance of the node\n",
    "        dist[source] = d\n",
    "        \n",
    "        #stop if the node we look at is the target obviously\n",
    "        if source == last_target:\n",
    "            break\n",
    "            \n",
    "        # Look at all direct descendents from the source node: \n",
    "        for target, edges in G_succ[source].items():\n",
    "            # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "            for edge_id in edges:\n",
    "                \n",
    "                # Get the duration between two nodes:\n",
    "                cost = graph.get_edge_data(source, target, edge_id)['duration']\n",
    "                \n",
    "                if cost is None:\n",
    "                        continue\n",
    "                \n",
    "                # Add the weight to the current distance of a node\n",
    "                current_dist = dist[source] + cost\n",
    "                \n",
    "                # if target has already been visited once and has a final distance:\n",
    "                if target in dist:\n",
    "                        # if we find a distance smaller than the actual distance in dic\n",
    "                        # raise error because dic distances contains only final distances\n",
    "                        if current_dist < dist[target]:\n",
    "                            raise ValueError('Contradictory paths found:',\n",
    "                                             'negative weights?')\n",
    "                # either node node been seen before or the current distance is smaller than the \n",
    "                # proposed distance in seen[target]:\n",
    "                elif target not in seen or current_dist < seen[target]:\n",
    "                    # update the seen distance\n",
    "                    seen[target] = current_dist\n",
    "                    # push it onto the heap so that we will look at its descendants later\n",
    "                    push(fringe, (current_dist, next(c), target))\n",
    "                    \n",
    "                    # update the paths till target:\n",
    "                    if paths is not None:\n",
    "                        paths[target] = paths[source] + [target]\n",
    "    if paths is not None:\n",
    "        return (dist, paths)\n",
    "    return dist\n",
    "\n",
    "def validate_path(path, confidence, graph):\n",
    "    #for _ in range(100):\n",
    "        #Validate path\n",
    "        #for e in path:\n",
    "            #sample_gaussian\n",
    "            #check if miss connection\n",
    "        #If > 0 connection missed, path missed\n",
    "    # if 95% must have missed < 5 path\n",
    "    # if path not validated -> starts with smaller threshold \n",
    "    return True\n",
    "\n",
    "def compute_delay_uncertainty(last_edge, confidence, null_gauss_count):\n",
    "    if confidence != None:\n",
    "        if 'mean' not in last_edge or 'std' not in last_edge:\n",
    "            null_gauss_count += 1\n",
    "            return 0, null_gauss_count\n",
    "        \n",
    "        mean, std = last_edge['mean'], last_edge['std']\n",
    "        num_sample = 50\n",
    "        t_quantile = stats.t(df=num_sample-1).ppf(confidence)\n",
    "        mean_deviation = t_quantile * std / np.sqrt(num_sample)\n",
    "        delay = mean_deviation\n",
    "        print(\"The delay induced for {}% confidence for edge ~ N({}, {}) is {}\"\n",
    "              .format(int(confidence*100), mean, std, delay))\n",
    "    else:\n",
    "        delay = 0\n",
    "        \n",
    "    return delay, null_gauss_count\n",
    "\n",
    "def dijkstra_with_time(G, first_source, arrival_time, last_target=None, confidence=None, paths=None):\n",
    "    while True:\n",
    "        departure_time = arrival_time - MAX_TRIP_DURATION*60\n",
    "\n",
    "        G_succ = G.succ if G.is_directed() else G.adj\n",
    "\n",
    "        paths = {first_source: [first_source]}\n",
    "        e_paths = {first_source: []}\n",
    "\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "        dist = {}  # dictionary of final distances\n",
    "\n",
    "        # dictionnary of wthether it's the first time a node is visited\n",
    "        seen = {first_source: departure_time}\n",
    "\n",
    "\n",
    "        c = count()\n",
    "        fringe = []  # use heapq with (distance,label) tuples\n",
    "\n",
    "        #push(fringe, (0, next(c), first_source))\n",
    "        push(fringe, (departure_time, next(c), first_source))\n",
    "\n",
    "        null_gauss_count = 0\n",
    "        while fringe:\n",
    "            #take the node to look at: \n",
    "            (d, _, source) = pop(fringe)\n",
    "            #print('Looking at node: '+source)\n",
    "\n",
    "            # check if node has already been looked at: \n",
    "            if source in dist:\n",
    "                continue  # already searched this node\n",
    "\n",
    "            # update the distance of the node\n",
    "            dist[source] = d\n",
    "\n",
    "            #stop if the node we look at is the target obviously\n",
    "            if source == last_target:\n",
    "                break\n",
    "\n",
    "                \n",
    "            # Look at all direct descendents from the source node: \n",
    "            for target, edges in G_succ[source].items():\n",
    "                # Because it's a multigraph, need to look at all edges between two nodes:\n",
    "                for edge_id in edges:\n",
    "                    # Check if walking edge\n",
    "                    dep_time_edge = graph.get_edge_data(source, target, edge_id)['time']\n",
    "                    if dep_time_edge == -1:\n",
    "                        walking_edge = True\n",
    "                        current_trip_id = None\n",
    "                        dep_time_edge = d\n",
    "                    else:\n",
    "                        walking_edge = False\n",
    "                        current_trip_id = graph.get_edge_data(source, target, edge_id)['trip_id']\n",
    "                        \n",
    "                    \n",
    "                    if dep_time_edge >= dist[source]:\n",
    "                        # Check if edge is feasible (also accoring to confidence)\n",
    "                        if len(e_paths[source]) >= 1 and not e_paths[source][-1][2]['walk']:\n",
    "                            last_edge_info = e_paths[source][-1][2]\n",
    "                            last_delay, null_gauss_count = compute_delay_uncertainty(last_edge_info, confidence, null_gauss_count)\n",
    "                            # If we make a transport-walk change, add delay to walk time\n",
    "                            if walking_edge:\n",
    "                                dep_time_edge += last_delay\n",
    "                            else:\n",
    "                                # If we make a transport-transport change, check if we have time\n",
    "                                if current_trip_id != last_edge_info['trip_id'] and dep_time_edge > dist[source] + 2 + last_delay:\n",
    "                                    continue\n",
    "\n",
    "                        # Get the duration between two nodes:\n",
    "                        duration_cost = graph.get_edge_data(source, target, edge_id)['duration']\n",
    "                        if duration_cost is None:\n",
    "                                continue\n",
    "\n",
    "                        # Add the weight to the current distance of a node\n",
    "                        current_dist = dep_time_edge + duration_cost\n",
    "\n",
    "                        # if target has already been visited once and has a final distance:\n",
    "                        if target in dist:\n",
    "                                # if we find a distance smaller than the actual distance in dic\n",
    "                                # raise error because dic distances contains only final distances\n",
    "                                if current_dist < dist[target]:\n",
    "                                    raise ValueError('Contradictory paths found:',\n",
    "                                                     'negative weights?')\n",
    "\n",
    "                        # either node has been seen before or the current distance is smaller than the \n",
    "                        # proposed distance in seen[target]:\n",
    "                        elif target not in seen or current_dist < seen[target]:\n",
    "                            # update the seen distance\n",
    "                            seen[target] = current_dist\n",
    "                            # push it onto the heap so that we will look at its descendants later\n",
    "                            push(fringe, (current_dist, next(c), target))\n",
    "\n",
    "                            # update the paths till target:\n",
    "                            if paths is not None:\n",
    "                                #paths[target] = paths[source] + [target]\n",
    "                                if walking_edge:\n",
    "                                    e_paths[target] = e_paths[source] + [(source, target, \n",
    "                                                                          {'departure_time':dep_time_edge, \n",
    "                                                                           'duration':duration_cost, \n",
    "                                                                           'walk': True})]\n",
    "                                else:\n",
    "                                    e_paths[target] = e_paths[source] + [(source, target, \n",
    "                                                                          {'departure_time':dep_time_edge,\n",
    "                                                                           'duration':duration_cost,\n",
    "                                                                           'walk': False,\n",
    "                                                                           'trip_id': current_trip_id})]\n",
    "\n",
    "        # No path exists\n",
    "        if  last_target not in e_paths:\n",
    "            print('Error: No paths to the source')\n",
    "            return (0, [])\n",
    "\n",
    "        \n",
    "        # Validation\n",
    "        if confidence == None or validate_path(e_paths[last_target], confidence, graph):\n",
    "            break\n",
    "        else:\n",
    "            confidence += confidence_step\n",
    "            \n",
    "    # Path validated\n",
    "    if paths is not None:\n",
    "        arrival_string = minute_to_string(dist[last_target])\n",
    "        best_path = e_paths[last_target]\n",
    "        departure_string = minute_to_string(best_path[0][2]['departure_time'])\n",
    "        \n",
    "        nodes_data = graph.nodes(data=True)\n",
    "        print('Going from {} ({}) to {} ({}) in {:.2f} minutes, departure at {}'.format(nodes_data[first_source]['name'],\n",
    "                                                                                      first_source,\n",
    "                                                                                      nodes_data[last_target]['name'],\n",
    "                                                                                      last_target, \n",
    "                                                                                      dist[last_target] - departure_time,\n",
    "                                                                                      minute_to_string(departure_time)))\n",
    "        \n",
    "        last_trip_id = False\n",
    "        for s, t, info in best_path:\n",
    "            if info['walk']:\n",
    "                last_trip_id = False\n",
    "                print('\\t{} ({}) -> {} ({}), {:.2f}\\' departure at {} on foot'.format(nodes_data[s]['name'], s,\n",
    "                                                                          nodes_data[t]['name'], t,\n",
    "                                                                          info['duration'],\n",
    "                                                                          minute_to_string(info['departure_time'])))\n",
    "            else:\n",
    "                if last_trip_id and last_trip_id == info['trip_id']:\n",
    "                    print('\\t{} ({}) -> {} ({}), {:.2f}\\' departure at {} (no change)'.format(nodes_data[s]['name'], s,\n",
    "                                                                          nodes_data[t]['name'], t,\n",
    "                                                                          info['duration'],\n",
    "                                                                          minute_to_string(info['departure_time'])))\n",
    "                else:\n",
    "                    last_trip_id = info['trip_id']\n",
    "                    print('\\t{} ({}) -> {} ({}), {:.2f}\\' departure at {}'.format(nodes_data[s]['name'], s,\n",
    "                                                                              nodes_data[t]['name'], t,\n",
    "                                                                              info['duration'],\n",
    "                                                                              minute_to_string(info['departure_time'])))\n",
    "        \n",
    "        return (dist[last_target], e_paths[last_target], null_gauss_count)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import pandas as pd\n",
    "username = os.environ['JUPYTERHUB_USER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges_with_mean_and_std_sec.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_times = pd.read_pickle('walking_edges.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'walking_times' as 'walking_times' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reverse edges\n",
    "#edges_walking = (walking_times.withColumnRenamed('source', 'temp')\n",
    "#                 .withColumnRenamed('target', 'source')\n",
    "#                 .withColumnRenamed('temp', 'target').toPandas())\n",
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['walk_duration']}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edges_for_trip(edges_df, day_id, arrival_time):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    min_dep_time = arrival_time - 60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_time))\n",
    "    \n",
    "    #reverse edges\n",
    "    #edges_df = (edges_df.withColumnRenamed('next_stop', 'temp')\n",
    "    #            .withColumnRenamed('stop_id', 'next_stop')\n",
    "    #            .withColumnRenamed('temp', 'stop_id'))\n",
    "\n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time']),\n",
    "                                                                       'trip_id': r['trip_id'],\n",
    "                                                                       'mean': r['mean'],\n",
    "                                                                       'std': r['std']})).collect()\n",
    "    print(edges[0])\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'8573195', u'8583890', {'duration': 2.0, 'std': 2.627700220351667, 'time': 643.0, 'trip_id': u'11.TA.1-217-j19-1.3.H', 'mean': 1.380964467005})"
     ]
    }
   ],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, arrival_hour*60+arrival_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 nodes removed"
     ]
    }
   ],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)\n",
    "\n",
    "old_number_of_nodes = graph.number_of_nodes()\n",
    "# Remove unreachable nodes\n",
    "dists, paths = normal_dijkstra(graph, '8503000')\n",
    "not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "_ = graph.remove_nodes_from(list(not_reachable))\n",
    "print('{} nodes removed'.format(old_number_of_nodes - graph.number_of_nodes()))\n",
    "\n",
    "# Temp for problem of encoding\n",
    "import unicodedata\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046632828786368166"
     ]
    }
   ],
   "source": [
    "# Proportion of null mean or std in non-walking edges\n",
    "(len(filter(lambda x: x[2]['mean'] == None or x[2]['std'] == None, filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True))))\n",
    " / float(len(filter(lambda x: 'mean' in x[2] and 'std' in x[2], graph.edges(data=True)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049) in 29.00 minutes, departure at 10:30\n",
      "\tZurich HB (8503000) -> Zurich HB (8503000:0:41/42), 2.14' departure at 10:30 on foot\n",
      "\tZurich HB (8503000:0:41/42) -> Zurich Hardbrucke (8503020:0:3), 2.00' departure at 10:37\n",
      "\tZurich Hardbrucke (8503020:0:3) -> Zurich Oerlikon (8503006:0:8), 5.00' departure at 10:39 (no change)\n",
      "\tZurich Oerlikon (8503006:0:8) -> Zurich Oerlikon, Bahnhof (8580449), 3.05' departure at 10:44 on foot\n",
      "\tZurich Oerlikon, Bahnhof (8580449) -> Zurich Oerlikon, Bahnhof Ost (8591063), 1.00' departure at 10:48\n",
      "\tZurich Oerlikon, Bahnhof Ost (8591063) -> Zurich, Leutschenbach (8591256), 2.00' departure at 10:50\n",
      "\tZurich, Leutschenbach (8591256) -> Zurich, Oerlikerhus (8591294), 0.00' departure at 10:52 (no change)\n",
      "\tZurich, Oerlikerhus (8591294) -> Glattpark, Glattpark (8591830), 2.00' departure at 10:52 (no change)\n",
      "\tGlattpark, Glattpark (8591830) -> Zurich, Fernsehstudio (8591128), 1.00' departure at 10:56\n",
      "\tZurich, Fernsehstudio (8591128) -> Zurich, Auzelg (8591049), 2.00' departure at 10:57 (no change)\n",
      "0"
     ]
    }
   ],
   "source": [
    "time, path, null_gauss_count = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049')\n",
    "null_gauss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich HB (8503000) to Zurich, Auzelg (8591049) in 29.00 minutes, departure at 10:30\n",
      "\tZurich HB (8503000) -> Zurich HB (8503000:0:41/42), 2.14' departure at 10:30 on foot\n",
      "\tZurich HB (8503000:0:41/42) -> Zurich Hardbrucke (8503020:0:3), 2.00' departure at 10:37\n",
      "\tZurich Hardbrucke (8503020:0:3) -> Zurich Oerlikon (8503006:0:8), 5.00' departure at 10:39 (no change)\n",
      "\tZurich Oerlikon (8503006:0:8) -> Zurich Oerlikon, Bahnhof (8580449), 3.05' departure at 10:44 on foot\n",
      "\tZurich Oerlikon, Bahnhof (8580449) -> Zurich Oerlikon, Bahnhof Ost (8591063), 1.00' departure at 10:48\n",
      "\tZurich Oerlikon, Bahnhof Ost (8591063) -> Zurich, Leutschenbach (8591256), 2.00' departure at 10:50\n",
      "\tZurich, Leutschenbach (8591256) -> Zurich, Oerlikerhus (8591294), 0.00' departure at 10:52 (no change)\n",
      "\tZurich, Oerlikerhus (8591294) -> Glattpark, Glattpark (8591830), 2.00' departure at 10:52 (no change)\n",
      "\tGlattpark, Glattpark (8591830) -> Zurich, Fernsehstudio (8591128), 1.00' departure at 10:56\n",
      "\tZurich, Fernsehstudio (8591128) -> Zurich, Auzelg (8591049), 2.00' departure at 10:57 (no change)\n",
      "29099"
     ]
    }
   ],
   "source": [
    "time, path, null_gauss_count = dijkstra_with_time(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049', confidence=0.9)\n",
    "null_gauss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'8503054', {'lat': 47.3649987828854, 'lon': 8.49519696319687, 'name': 'Zurich Triemli'}), (u'8503610', {'lat': 47.3681504693771, 'lon': 8.49537662625372, 'name': 'Zurich, Triemli'}), (u'8591401', {'lat': 47.3663860348906, 'lon': 8.4967690149443, 'name': 'Zurich, Triemlispital'})]\n",
      "[(u'8503001:0:2', {'lat': 47.3917881971539, 'lon': 8.48893570566569, 'name': 'Zurich Altstetten'}), (u'8503001:0:3', {'lat': 47.3915449394745, 'lon': 8.48893570566569, 'name': 'Zurich Altstetten'}), (u'8503001:0:4', {'lat': 47.3916057539996, 'lon': 8.48893570566569, 'name': 'Zurich Altstetten'}), (u'8503001:0:6', {'lat': 47.3916665684545, 'lon': 8.48893570566569, 'name': 'Zurich Altstetten'}), (u'8503001:0:7', {'lat': 47.3917273828393, 'lon': 8.48893570566569, 'name': 'Zurich Altstetten'}), (u'8503001P', {'lat': 47.3914841248792, 'lon': 8.48893570566569, 'name': 'Zurich Altstetten'}), (u'8591057', {'lat': 47.392067942097, 'lon': 8.48990588617267, 'name': 'Zurich Altstetten, Bahnhof N'}), (u'8591056', {'lat': 47.3911070728222, 'lon': 8.48837875018946, 'name': 'Zurich Altstetten, Bahnhof'})]"
     ]
    }
   ],
   "source": [
    "print(filter(lambda x: 'Triemli' in x[1]['name'], graph.nodes(data=True)))\n",
    "print(filter(lambda x: 'Altstetten' in x[1]['name'], graph.nodes(data=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057) in 17.14 minutes, departure at 10:30\n",
      "\tZurich, Triemli (8503610) -> Zurich, In der Ey (8591214), 1.00' departure at 10:31\n",
      "\tZurich, In der Ey (8591214) -> Zurich, Goldackerweg (8591163), 1.00' departure at 10:32 (no change)\n",
      "\tZurich, Goldackerweg (8591163) -> Zurich, Albisrieden (8591036), 2.00' departure at 10:33 (no change)\n",
      "\tZurich, Albisrieden (8591036) -> Zurich, Albisriederdorfli (8591037), 0.00' departure at 10:35 (no change)\n",
      "\tZurich, Albisriederdorfli (8591037) -> Zurich, Untermoosstrasse (8591408), 2.00' departure at 10:35 (no change)\n",
      "\tZurich, Untermoosstrasse (8591408) -> Zurich, Rautistrasse (8591311), 1.00' departure at 10:37 (no change)\n",
      "\tZurich, Rautistrasse (8591311) -> Zurich, Lindenplatz (8591258), 2.00' departure at 10:38 (no change)\n",
      "\tZurich, Lindenplatz (8591258) -> Zurich, Bristenstrasse (8591097), 1.00' departure at 10:40 (no change)\n",
      "\tZurich, Bristenstrasse (8591097) -> Zurich Altstetten, Bahnhof (8591056), 1.00' departure at 10:41 (no change)\n",
      "\tZurich Altstetten, Bahnhof (8591056) -> Zurich Altstetten, Bahnhof N (8591057), 5.14' departure at 10:42 on foot"
     ]
    }
   ],
   "source": [
    "time, path, null_gauss_count = dijkstra_with_time(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057', confidence=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'duration': 2.0, 'std': 2.04106382892, 'time': 738.0, 'trip_id': u'1227.TA.26-80-j19-1.8.R', 'mean': 1.2843136156550001}, 1: {'duration': 2.0, 'std': 2.04106382892, 'time': 723.0, 'trip_id': u'1236.TA.26-80-j19-1.8.R', 'mean': 1.2843136156550001}, 2: {'duration': 2.0, 'std': 1.5378574563483334, 'time': 708.0, 'trip_id': u'1250.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 3: {'duration': 2.0, 'std': 1.5378574563483334, 'time': 693.0, 'trip_id': u'1257.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 4: {'duration': 2.0, 'std': 1.5378574563483334, 'time': 678.0, 'trip_id': u'1272.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 5: {'duration': 2.0, 'std': 1.5378574563483334, 'time': 663.0, 'trip_id': u'1286.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 6: {'duration': 2.0, 'std': 1.5585312253966668, 'time': 648.0, 'trip_id': u'1305.TA.26-80-j19-1.8.R', 'mean': 1.2626964433416668}, 7: {'duration': 2.0, 'std': 1.5585312253966668, 'time': 633.0, 'trip_id': u'1317.TA.26-80-j19-1.8.R', 'mean': 1.2626964433416668}, 8: {'duration': 1.0, 'std': 2.04106382892, 'time': 731.0, 'trip_id': u'1235.TA.26-80-j19-1.8.R', 'mean': 1.2843136156550001}, 9: {'duration': 1.0, 'std': 1.5378574563483334, 'time': 716.0, 'trip_id': u'1243.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 10: {'duration': 1.0, 'std': 1.5378574563483334, 'time': 701.0, 'trip_id': u'1251.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 11: {'duration': 1.0, 'std': 1.5378574563483334, 'time': 686.0, 'trip_id': u'1265.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 12: {'duration': 1.0, 'std': 1.5378574563483334, 'time': 671.0, 'trip_id': u'1279.TA.26-80-j19-1.8.R', 'mean': 1.2908743475016666}, 13: {'duration': 1.0, 'std': 1.5585312253966668, 'time': 656.0, 'trip_id': u'1295.TA.26-80-j19-1.8.R', 'mean': 1.2626964433416668}, 14: {'duration': 1.0, 'std': 1.5585312253966668, 'time': 641.0, 'trip_id': u'1306.TA.26-80-j19-1.8.R', 'mean': 1.2626964433416668}, 15: {'duration': 1.0, 'std': 2.04106382892, 'time': 746.0, 'trip_id': u'1365.TA.26-80-j19-1.8.R', 'mean': 1.2843136156550001}, 16: {'duration': 9.3016717529, 'time': -1}}"
     ]
    }
   ],
   "source": [
    "graph.get_edge_data('8591163', '8591036')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
